---
title: ç¬¬17ç« ï¼šä¸»æµæ•°æ®åº“ä¸ä¼ä¸šçº§åº”ç”¨
---

# ï¼šä¸»æµæ•°æ®åº“ä¸ä¼ä¸šçº§åº”ç”¨

> **éš¾åº¦ç­‰çº§**ï¼šâ­â­â­ | **å­¦ä¹ æ—¶é•¿**ï¼š2å‘¨ | **å®æˆ˜é¡¹ç›®**ï¼š3ä¸ª

## ğŸ“š æœ¬ç« ç›®å½•

- [17.1 æ•°æ®åº“æŠ€æœ¯æ ˆæ¦‚è§ˆ](#171-æ•°æ®åº“æŠ€æœ¯æ ˆæ¦‚è§ˆ)
- [17.2 MySQL 8.0+ ä¼ä¸šçº§å®è·µ](#172-mysql-80-ä¼ä¸šçº§å®è·µ)
- [17.3 PostgreSQL 16+ é«˜çº§ç‰¹æ€§](#173-postgresql-16-é«˜çº§ç‰¹æ€§)
- [17.4 å›½äº§åˆ†å¸ƒå¼æ•°æ®åº“](#174-å›½äº§åˆ†å¸ƒå¼æ•°æ®åº“)
- [17.5 NoSQL æ•°æ®åº“å®æˆ˜](#175-nosql-æ•°æ®åº“å®æˆ˜)
- [17.6 æ—¶åºæ•°æ®åº“ä¸å‘é‡æ•°æ®åº“](#176-æ—¶åºæ•°æ®åº“ä¸å‘é‡æ•°æ®åº“)
- [17.7 æ•°æ®åº“é€‰å‹ä¸æ¶æ„è®¾è®¡](#177-æ•°æ®åº“é€‰å‹ä¸æ¶æ„è®¾è®¡)
- [17.8 å®æˆ˜é¡¹ç›®](#178-å®æˆ˜é¡¹ç›®)

---

## æ•°æ®åº“æŠ€æœ¯æ ˆæ¦‚è§ˆ

### æ•°æ®åº“åˆ†ç±»å›¾è°±

```mermaid
mindmap
  root((æ•°æ®åº“æŠ€æœ¯æ ˆ 2026))
    å…³ç³»å‹æ•°æ®åº“
      MySQL 8.0+
      PostgreSQL 16+
      Oracle 23c
      SQL Server 2022
    å›½äº§æ•°æ®åº“
      OceanBase
      TiDB
      è¾¾æ¢¦ DM
      openGauss
      GaussDB
      TDSQL
    NoSQL
      æ–‡æ¡£å‹: MongoDB
      é”®å€¼å‹: Redis
      åˆ—æ—å‹: HBase
      å›¾æ•°æ®åº“: Neo4j
    NewSQL
      TiDB
      CockroachDB
      OceanBase
    æ—¶åºæ•°æ®åº“
      InfluxDB
      TDengine
      TimescaleDB
    å‘é‡æ•°æ®åº“
      Milvus
      Pinecone
      Weaviate
    æœç´¢å¼•æ“
      Elasticsearch
      OpenSearch
      Solr
```

### æ•°æ®åº“é€‰å‹å†³ç­–è¡¨

| ä¸šåŠ¡åœºæ™¯ | æ¨èæ•°æ®åº“ | å¤‡é€‰æ–¹æ¡ˆ | æ ¸å¿ƒä¼˜åŠ¿ |
|---------|-----------|---------|---------|
| **ç”µå•†è®¢å•** | MySQL | TiDB/TDSQL | æˆç†Ÿç¨³å®šã€ç”Ÿæ€å®Œå–„ |
| **é‡‘èæ ¸å¿ƒ** | OceanBase | GaussDB | é‡‘èçº§é«˜å¯ç”¨ã€å¼ºä¸€è‡´ |
| **ç¤¾äº¤ç½‘ç»œ** | PostgreSQL | MongoDB | å¤æ‚æŸ¥è¯¢èƒ½åŠ›å¼º |
| **ç‰©è”ç½‘** | TDengine | InfluxDB | å‹ç¼©ç‡é«˜ã€å†™å…¥å¿« |
| **æ—¥å¿—åˆ†æ** | ClickHouse | Elasticsearch | åˆ—å­˜ã€æŸ¥è¯¢å¿« |
| **å†…å®¹ç®¡ç†** | MongoDB | PostgreSQL | çµæ´»çš„æ–‡æ¡£æ¨¡å‹ |
| **AIåº”ç”¨** | PostgreSQL + Milvus | Pinecone | å‘é‡æœç´¢èƒ½åŠ› |
| **æœç´¢å¼•æ“** | Elasticsearch | OpenSearch | å…¨æ–‡æ£€ç´¢ |
| **ç¼“å­˜** | Redis | Memcached | ä¸°å¯Œçš„æ•°æ®ç»“æ„ |

---

## MySQL 8.0+ ä¼ä¸šçº§å®è·µ

### å®‰è£…ä¸é…ç½®

**Docker å¿«é€Ÿéƒ¨ç½²**ï¼š
```bash
# æ‹‰å–MySQL 8.0é•œåƒ
docker pull mysql:8.0

# å¯åŠ¨å®¹å™¨
docker run -d \
    --name mysql8 \
    -p 3306:3306 \
    -e MYSQL_ROOT_PASSWORD=yourpassword \
    -v /data/mysql:/var/lib/mysql \
    -v /data/mysql-conf:/etc/mysql/conf.d \
    mysql:8.0 \
    --character-set-server=utf8mb4 \
    --collation-server=utf8mb4_unicode_ci
```

**my.cnf ä¼˜åŒ–é…ç½®**ï¼š
```ini
[mysqld]
# åŸºç¡€é…ç½®
server-id = 1
port = 3306
datadir = /var/lib/mysql
socket = /var/lib/mysql/mysql.sock
pid-file = /var/run/mysqld/mysqld.pid

# å­—ç¬¦é›†
character-set-server = utf8mb4
collation-server = utf8mb4_unicode_ci

# InnoDBé…ç½®
innodb_buffer_pool_size = 4G
innodb_log_file_size = 512M
innodb_flush_log_at_trx_commit = 1
innodb_flush_method = O_DIRECT
innodb_file_per_table = 1
innodb_io_capacity = 2000
innodb_io_capacity_max = 4000

# è¿æ¥é…ç½®
max_connections = 1000
max_connect_errors = 100000
wait_timeout = 28800
interactive_timeout = 28800

# æ…¢æŸ¥è¯¢æ—¥å¿—
slow_query_log = 1
slow_query_log_file = /var/log/mysql/slow.log
long_query_time = 1

# Binlogé…ç½®
log_bin = mysql-bin
binlog_format = ROW
binlog_expire_logs_seconds = 604800
expire_logs_days = 7

# æ€§èƒ½ä¼˜åŒ–
performance_schema = ON
table_open_cache = 4000
table_definition_cache = 2000
```

### çª—å£å‡½æ•°å®æˆ˜

```sql
-- 1. ROW_NUMBERï¼šè¿ç»­æ’å
SELECT
    emp_id,
    emp_name,
    department,
    salary,
    ROW_NUMBER() OVER (PARTITION BY department ORDER BY salary DESC) as ranking
FROM employees
WHERE department = 'Technology';

-- ç»“æœï¼šå³ä½¿è–ªèµ„ç›¸åŒï¼Œæ’åä¹Ÿè¿ç»­
-- emp_id | emp_name | salary | ranking
-- 1001   | Alice    | 50000  | 1
-- 1002   | Bob      | 50000  | 2
-- 1003   | Charlie  | 45000  | 3

-- 2. RANKï¼šè·³è·ƒæ’å
SELECT
    emp_id,
    emp_name,
    salary,
    RANK() OVER (ORDER BY salary DESC) as rank_ranking
FROM employees;

-- ç»“æœï¼šç›¸åŒè–ªèµ„æ’åç›¸åŒï¼Œä¸‹ä¸€ä¸ªæ’åè·³è·ƒ
-- emp_id | emp_name | salary | ranking
-- 1001   | Alice    | 50000  | 1
-- 1002   | Bob      | 50000  | 1
-- 1003   | Charlie  | 45000  | 3

-- 3. DENSE_RANKï¼šå¯†é›†æ’å
SELECT
    emp_id,
    emp_name,
    salary,
    DENSE_RANK() OVER (ORDER BY salary DESC) as dense_rank
FROM employees;

-- ç»“æœï¼šç›¸åŒè–ªèµ„æ’åç›¸åŒï¼Œä¸‹ä¸€ä¸ªæ’åä¸è·³è·ƒ
-- emp_id | emp_name | salary | ranking
-- 1001   | Alice    | 50000  | 1
-- 1002   | Bob      | 50000  | 1
-- 1003   | Charlie  | 45000  | 2

-- 4. ç§»åŠ¨å¹³å‡ï¼ˆè®¡ç®—3å¤©ç§»åŠ¨å¹³å‡ï¼‰
SELECT
    order_date,
    daily_sales,
    AVG(daily_sales) OVER (
        ORDER BY order_date
        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    ) as moving_avg_3day
FROM daily_sales_summary;

-- 5. ç´¯è®¡æ±‚å’Œ
SELECT
    order_date,
    daily_sales,
    SUM(daily_sales) OVER (
        ORDER BY order_date
        ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW
    ) as cumulative_sales
FROM daily_sales_summary;

-- 6. åŒæ¯”/ç¯æ¯”è®¡ç®—
SELECT
    curr.order_date,
    curr.daily_sales,
    curr.daily_sales - prev.daily_sales as mom_growth,  -- ç¯æ¯”å¢é•¿
    curr.daily_sales / prev.daily_sales - 1 as mom_rate  -- ç¯æ¯”å¢é•¿ç‡
FROM daily_sales_summary curr
LEFT JOIN daily_sales_summary prev
    ON curr.order_date = DATE_ADD(prev.order_date, INTERVAL 1 DAY);
```

### CTE é€’å½’æŸ¥è¯¢

```sql
-- 1. é€’å½’æŸ¥è¯¢ç»„ç»‡æ¶æ„æ ‘
WITH RECURSIVE org_tree AS (
    -- åŸºç¡€æŸ¥è¯¢ï¼šæ ¹èŠ‚ç‚¹ï¼ˆCEOï¼‰
    SELECT
        id,
        name,
        parent_id,
        1 as level,
        CAST(name AS CHAR(1000)) as path
    FROM employees
    WHERE parent_id IS NULL

    UNION ALL

    -- é€’å½’æŸ¥è¯¢ï¼šæ‰€æœ‰å­èŠ‚ç‚¹
    SELECT
        e.id,
        e.name,
        e.parent_id,
        ot.level + 1,
        CONCAT(ot.path, ' > ', e.name) as path
    FROM employees e
    INNER JOIN org_tree ot ON e.parent_id = ot.id
)
SELECT * FROM org_tree ORDER BY level, id;

-- 2. é€’å½’æŸ¥è¯¢ç‰©æ–™æ¸…å•ï¼ˆBOMï¼‰
WITH RECURSIVE bom_tree AS (
    -- åŸºç¡€ï¼šé¡¶å±‚äº§å“
    SELECT
        p.product_id,
        p.product_name,
        p.quantity,
        p.unit_cost,
        p.quantity * p.unit_cost as total_cost,
        1 as level
    FROM products p
    WHERE product_id = 1001  -- æˆå“ID

    UNION ALL

    -- é€’å½’ï¼šæ‰€æœ‰å­ç»„ä»¶
    SELECT
        c.component_id,
        c.component_name,
        p.quantity * c.quantity as total_quantity,  -- ç´¯è®¡æ•°é‡
        c.unit_cost,
        p.quantity * c.quantity * c.unit_cost as total_cost,
        bt.level + 1
    FROM bom_tree bt
    INNER JOIN product_components pc ON bt.product_id = pc.product_id
    INNER JOIN components c ON pc.component_id = c.component_id
)
SELECT * FROM bom_tree;

-- 3. ç”Ÿæˆæ—¥æœŸåºåˆ—
WITH RECURSIVE date_series AS (
    SELECT DATE('2024-01-01') as date
    UNION ALL
    SELECT DATE_ADD(date, INTERVAL 1 DAY)
    FROM date_series
    WHERE date < '2024-12-31'
)
SELECT date FROM date_series;

-- 4. æ‰¾å‡ºç¼ºå¤±çš„ID
WITH RECURSIVE all_ids AS (
    SELECT 1 as id
    UNION ALL
    SELECT id + 1 FROM all_ids WHERE id < 1000
)
SELECT id FROM all_ids
WHERE id NOT IN (SELECT id FROM orders)
LIMIT 100;
```

### JSON æ•°æ®ç±»å‹

```sql
-- 1. åˆ›å»ºJSONè¡¨
CREATE TABLE products (
    id INT PRIMARY KEY AUTO_INCREMENT,
    name VARCHAR(100),
    attributes JSON,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 2. æ’å…¥JSONæ•°æ®
INSERT INTO products (name, attributes) VALUES
('iPhone 15 Pro', '{
    "color": "é’›é‡‘å±ç°",
    "storage": "256GB",
    "price": 8999,
    "specs": {
        "chip": "A17 Pro",
        "ram": "8GB",
        "screen": "6.1è‹±å¯¸"
    },
    "features": ["5G", "Face ID", "USB-C"]
}');

-- 3. æŸ¥è¯¢JSONå­—æ®µ
SELECT
    name,
    JSON_EXTRACT(attributes, '$.color') as color,
    JSON_EXTRACT(attributes, '$.specs.chip') as chip,
    attributes->>'$.price' as price  -- ç®€å†™æ–¹å¼
FROM products;

-- 4. JSONç´¢å¼•ï¼ˆMySQL 8.0.17+ï¼‰
-- åˆ›å»ºç”Ÿæˆåˆ—å¹¶ç´¢å¼•
ALTER TABLE products
ADD COLUMN color_virtual VARCHAR(20)
    AS (attributes->>'$.color') VIRTUAL,
ADD INDEX idx_color (color_virtual);

-- 5. JSONæ•°ç»„æŸ¥è¯¢
SELECT name, attributes
FROM products
WHERE JSON_CONTAINS(attributes->>'$.features', '"5G"');

-- 6. JSONæœç´¢
SELECT
    name,
    attributes->>'$.specs.screen' as screen
FROM products
WHERE JSON_SEARCH(attributes, 'one', '256GB') IS NOT NULL;

-- 7. JSONä¿®æ”¹
UPDATE products
SET attributes = JSON_SET(attributes, '$.price', 7999)
WHERE id = 1;

-- 8. JSONèšåˆ
SELECT
    JSON_ARRAYAGG(attributes->>'$.color') as colors
FROM products
WHERE name LIKE 'iPhone%';
```

### Spring Boot æ•´åˆ MySQL

**application.yml é…ç½®**ï¼š
```yaml
spring:
  datasource:
    driver-class-name: com.mysql.cj.jdbc.Driver
    url: jdbc:mysql://localhost:3306/demo?useUnicode=true&characterEncoding=utf8&useSSL=false&serverTimezone=Asia/Shanghai
    username: root
    password: password
    hikari:
      maximum-pool-size: 20
      minimum-idle: 5
      connection-timeout: 30000
      idle-timeout: 600000
      max-lifetime: 1800000

  jpa:
    hibernate:
      ddl-auto: update
    show-sql: true
    properties:
      hibernate:
        dialect: org.hibernate.dialect.MySQL8Dialect
        format_sql: true
```

**å®ä½“ç±»å®šä¹‰**ï¼š
```java
@Entity
@Table(name = "orders")
@Data
public class Order {

    @Id
    @GeneratedValue(strategy = GenerationType.IDENTITY)
    private Long id;

    private Long userId;
    private Long productId;

    private BigDecimal amount;

    @Enumerated(EnumType.STRING)
    private OrderStatus status;

    @Column(name = "created_at", updatable = false)
    @CreationTimestamp
    private LocalDateTime createdAt;

    @Column(name = "updated_at")
    @UpdateTimestamp
    private LocalDateTime updatedAt;

    // JSONå­—æ®µï¼ˆJPA 2.1+ï¼‰
    @Convert(converter = JsonConverter.class)
    @Column(columnDefinition = "json")
    private Map<String, Object> metadata;
}

// JSONè½¬æ¢å™¨
@Converter
public class JsonConverter implements AttributeConverter<Map<String, Object>, String> {

    private final ObjectMapper objectMapper = new ObjectMapper();

    @Override
    public String convertToDatabaseColumn(Map<String, Object> attribute) {
        try {
            return objectMapper.writeValueAsString(attribute);
        } catch (JsonProcessingException e) {
            throw new RuntimeException("JSONè½¬æ¢å¤±è´¥", e);
        }
    }

    @Override
    @SuppressWarnings("unchecked")
    public Map<String, Object> convertToEntityAttribute(String dbData) {
        try {
            return objectMapper.readValue(dbData, Map.class);
        } catch (JsonProcessingException e) {
            return new HashMap<>();
        }
    }
}
```

---

## PostgreSQL 16+ é«˜çº§ç‰¹æ€§

### å®‰è£…ä¸é…ç½®

**Docker éƒ¨ç½²**ï¼š
```bash
docker run -d \
    --name postgres16 \
    -p 5432:5432 \
    -e POSTGRES_PASSWORD=yourpassword \
    -e POSTGRES_DB=mydb \
    -v /data/postgres:/var/lib/postgresql/data \
    -v /data/postgres-conf:/etc/postgresql \
    postgres:16
```

**postgres.conf ä¼˜åŒ–**ï¼š
```ini
# è¿æ¥è®¾ç½®
max_connections = 200
shared_buffers = 4GB
effective_cache_size = 12GB
maintenance_work_mem = 1GB
work_mem = 16MB

# WALè®¾ç½®
wal_buffers = 16MB
max_wal_size = 4GB
min_wal_size = 1GB
wal_level = replica

# æŸ¥è¯¢ä¼˜åŒ–
random_page_cost = 1.1  # SSDå­˜å‚¨
effective_io_concurrency = 200
max_worker_processes = 8
max_parallel_workers_per_gather = 4
max_parallel_workers = 8

# æ—¥å¿—
logging_collector = on
log_directory = 'log'
log_filename = 'postgresql-%Y-%m-%d_%H%M%S.log'
log_min_duration_statement = 1000
```

### é«˜çº§æ•°æ®ç±»å‹

```sql
-- 1. æ•°ç»„ç±»å‹
CREATE TABLE posts (
    id SERIAL PRIMARY KEY,
    title VARCHAR(200),
    tags TEXT[],  -- æ–‡æœ¬æ•°ç»„
    categories INT[]
);

-- æ’å…¥æ•°ç»„æ•°æ®
INSERT INTO posts (title, tags, categories)
VALUES ('PostgreSQLæ•™ç¨‹', ARRAY['æ•°æ®åº“', 'SQL', 'PostgreSQL'], ARRAY[1, 2, 3]);

-- æŸ¥è¯¢æ•°ç»„
SELECT * FROM posts WHERE 'æ•°æ®åº“' = ANY(tags);
SELECT * FROM posts WHERE tags @> ARRAY['PostgreSQL'];  -- åŒ…å«
SELECT * FROM posts WHERE tags && ARRAY['SQL', 'NoSQL'];  -- é‡å 

-- 2. JSONBç±»å‹ï¼ˆäºŒè¿›åˆ¶JSONï¼Œæ€§èƒ½æ›´å¥½ï¼‰
CREATE TABLE events (
    id SERIAL PRIMARY KEY,
    event_data JSONB,
    created_at TIMESTAMP DEFAULT NOW()
);

-- åˆ›å»ºGINç´¢å¼•
CREATE INDEX idx_events_data ON events USING GIN (event_data);

-- JSONBæŸ¥è¯¢
SELECT * FROM events
WHERE event_data @> '{"user": {"id": 123}}';  -- åŒ…å«

SELECT event_data->>'user'->>'name' as user_name
FROM events
WHERE event_data->>'action' = 'click';

-- JSONBæ›´æ–°
UPDATE events
SET event_data = jsonb_set(event_data, '{count}', ((event_data->>'count')::int + 1)::text::jsonb)
WHERE id = 1;

-- 3. èŒƒå›´ç±»å‹
CREATE TABLE meetings (
    id SERIAL PRIMARY KEY,
    title VARCHAR(200),
    duration TSRANGE,  -- æ—¶é—´æˆ³èŒƒå›´
    price_range NUMRANGE  -- æ•°å€¼èŒƒå›´
);

-- æ’å…¥èŒƒå›´æ•°æ®
INSERT INTO meetings (title, duration, price_range)
VALUES (
    'æŠ€æœ¯åˆ†äº«',
    '[2024-01-01 14:00, 2024-01-01 16:00]',
    '[100, 500]'
);

-- èŒƒå›´æŸ¥è¯¢
SELECT * FROM meetings
WHERE duration && '[2024-01-01 15:00, 2024-01-01 17:00]'::tsrange;

-- 4. å…¨æ–‡æœç´¢
CREATE TABLE articles (
    id SERIAL PRIMARY KEY,
    title TEXT,
    content TEXT,
    tsv tsvector  -- å…¨æ–‡æœç´¢å‘é‡
);

-- è‡ªåŠ¨æ›´æ–°tsv
CREATE INDEX idx_articles_tsv ON articles USING GIN (tsv);

CREATE TRIGGER tsvector_update
BEFORE INSERT OR UPDATE ON articles
FOR EACH ROW
EXECUTE FUNCTION
    tsvector_update_trigger(tsv, 'pg_catalog.simple', title, content);

-- å…¨æ–‡æœç´¢
SELECT title, content
FROM articles
WHERE tsv @@ to_tsquery('simple', 'PostgreSQL & æ•°æ®åº“')
ORDER BY ts_rank(tsv, to_tsquery('simple', 'PostgreSQL & æ•°æ®åº“')) DESC;

-- é«˜äº®æ˜¾ç¤º
SELECT
    title,
    ts_headline('simple', content, to_tsquery('simple', 'æ•°æ®åº“'))
FROM articles
WHERE tsv @@ to_tsquery('simple', 'æ•°æ®åº“');
```

### çª—å£å‡½æ•°é«˜çº§åº”ç”¨

```sql
-- 1. æ—¶é—´åºåˆ—åˆ†æ
WITH monthly_sales AS (
    SELECT
        DATE_TRUNC('month', order_date) as month,
        SUM(amount) as total
    FROM orders
    GROUP BY month
)
SELECT
    month,
    total,
    LAG(total) OVER (ORDER BY month) as prev_month,
    total - LAG(total) OVER (ORDER BY month) as growth,
    ROUND(
        (total - LAG(total) OVER (ORDER BY month)) /
        LAG(total) OVER (ORDER BY month) * 100, 2
    ) as growth_rate
FROM monthly_sales;

-- 2. ä¼šè¯åˆ†æï¼ˆè¯†åˆ«ç”¨æˆ·ä¼šè¯ï¼‰
WITH user_actions AS (
    SELECT
        user_id,
        action_time,
        -- å¦‚æœä¸å‰ä¸€æ¬¡æ“ä½œé—´éš”è¶…è¿‡30åˆ†é’Ÿï¼Œåˆ™è®¤ä¸ºæ˜¯æ–°ä¼šè¯
        SUM(CASE
            WHEN action_time - LAG(action_time) OVER (PARTITION BY user_id ORDER BY action_time) > INTERVAL '30 minutes'
            THEN 1
            ELSE 0
        END) OVER (PARTITION BY user_id ORDER BY action_time) as session_id
    FROM user_activity
)
SELECT
    user_id,
    session_id,
    MIN(action_time) as session_start,
    MAX(action_time) as session_end,
    COUNT(*) as action_count
FROM user_actions
GROUP BY user_id, session_id
ORDER BY user_id, session_start;
```

### Spring Data JPA æ•´åˆ

**ä¾èµ–é…ç½®**ï¼š
```xml
<dependency>
    <groupId>org.postgresql</groupId>
    <artifactId>postgresql</artifactId>
</dependency>
```

**å®ä½“ç±»**ï¼š
```java
@Entity
@Table(name = "products")
@Data
public class Product {

    @Id
    @GeneratedValue(strategy = GenerationType.IDENTITY)
    private Long id;

    private String name;

    // PostgreSQLæ•°ç»„æ˜ å°„
    @Column(columnDefinition = "text[]")
    @Type(PostgreSQLEnumType.class)
    private List<String> tags;

    // JSONBæ˜ å°„
    @Type(type = "json")
    @Column(columnDefinition = "jsonb")
    private Map<String, Object> attributes;

    // èŒƒå›´ç±»å‹æ˜ å°„
    @Column(columnDefinition = "numrange")
    private String priceRange;
}

// è‡ªå®šä¹‰ç±»å‹
public class PostgreSQLEnumType implements UserType {

    @Override
    public int[] sqlTypes() {
        return new int[]{Types.ARRAY};
    }

    @Override
    public Class returnedClass() {
        return List.class;
    }

    @Override
    public Object nullSafeGet(ResultSet rs, String[] names, SharedSessionContractImplementor session, Object owner)
            throws SQLException {
        Array array = rs.getArray(names[0]);
        return array != null ? Arrays.asList((Object[]) array.getArray()) : null;
    }

    @Override
    public void nullSafeSet(PreparedStatement st, Object value, int index, SharedSessionContractImplementor session)
            throws SQLException {
        if (value == null) {
            st.setNull(index, Types.ARRAY);
        } else {
            Connection connection = st.getConnection();
            Array array = connection.createArrayOf("text", ((List<?>) value).toArray());
            st.setArray(index, array);
        }
    }
}
```

---

## å›½äº§åˆ†å¸ƒå¼æ•°æ®åº“

### OceanBase å®æˆ˜

**Docker éƒ¨ç½² OceanBase**ï¼š
```bash
# æ‹‰å–é•œåƒ
docker pull oceanbase/oceanbase-ce:4.2

# å¯åŠ¨å•æœºç‰ˆ
docker run -d \
    --name oceanbase \
    -p 2881:2881 -p 2882:2882 \
    -e MODE=mini \
    -e OB_CLUSTER_NAME=obcluster \
    -e OB_TENANT_NAME=mytenant \
    -e OB_MEMORY_LIMIT=8G \
    oceanbase/oceanbase-ce:4.2
```

**è¿æ¥ OceanBase**ï¼š
```bash
# ä½¿ç”¨ obclient
obclient -h127.0.0.1 -P2881 -uroot@sys -p

# æˆ–è€…ä½¿ç”¨ MySQL å®¢æˆ·ç«¯ï¼ˆå…¼å®¹åè®®ï¼‰
mysql -h127.0.0.1 -P2881 -uroot@sys
```

**åˆ›å»ºç§Ÿæˆ·**ï¼š
```sql
-- åˆ›å»ºèµ„æºæ± 
CREATE RESOURCE UNIT unit_4c16g
    MEMORY_SIZE = '16G',
    MIN_CPU = 4,
    MAX_CPU = 4;

-- åˆ›å»ºèµ„æºæ± 
CREATE RESOURCE POOL pool_mysql
    UNIT = 'unit_4c16g',
    UNIT_NUM = 1;

-- åˆ›å»º MySQL ç§Ÿæˆ·
CREATE TENANT tenant_mysql
    RESOURCE_POOL_LIST = ('pool_mysql'),
    SET ob_tcp_invited_nodes = '%',
    SET ob_compatibility_mode = 'MYSQL';

-- è¿æ¥åˆ°æ–°ç§Ÿæˆ·
mysql -h127.0.0.1 -P2881 -uroot@tenant_mysql
```

**åˆ†åŒºè¡¨è®¾è®¡**ï¼š
```sql
-- Hashåˆ†åŒºï¼ˆæŒ‰ä¸»é”®ï¼‰
CREATE TABLE orders (
    order_id BIGINT PRIMARY KEY,
    user_id BIGINT NOT NULL,
    product_id BIGINT NOT NULL,
    amount DECIMAL(10,2),
    status VARCHAR(32),
    create_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP
) PARTITION BY HASH(order_id)
PARTITIONS 128;

-- Rangeåˆ†åŒºï¼ˆæŒ‰æ—¶é—´ï¼‰
CREATE TABLE orders_by_date (
    order_id BIGINT,
    create_time TIMESTAMP,
    amount DECIMAL(10,2),
    PRIMARY KEY (order_id, create_time)
) PARTITION BY RANGE (TO_DAYS(create_time)) (
    PARTITION p202401 VALUES LESS THAN (TO_DAYS('2024-02-01')),
    PARTITION p202402 VALUES LESS THAN (TO_DAYS('2024-03-01')),
    PARTITION p202403 VALUES LESS THAN (TO_DAYS('2024-04-01')),
    PARTITION pmax VALUES LESS THAN MAXVALUE
);

-- å…¨å±€ç´¢å¼•
CREATE UNIQUE GLOBAL INDEX idx_user_orders
ON orders(user_id, order_id)
PARTITION BY HASH(user_id) PARTITIONS 64;
```

### TiDB å®æˆ˜

**æœ¬åœ°éƒ¨ç½² TiDB**ï¼š
```bash
# ä½¿ç”¨ TiUP éƒ¨ç½²
curl --proto '=https' --tlsv1.2 -sSf https://tiup-mirrors.pingcap.com/install.sh | sh
source .bash_profile
tiup playground

# æˆ–è€…ä½¿ç”¨ Docker
docker-compose up -d
# docker-compose.yml:
# version: '3'
# services:
#   tidb:
#     image: pingcap/tidb:latest
#     ports:
#       - "4000:4000"
#       - "10080:10080"
```

**åˆ›å»º TiFlash å‰¯æœ¬**ï¼š
```sql
-- åˆ›å»ºè¡¨
CREATE TABLE orders (
    order_id BIGINT PRIMARY KEY,
    user_id BIGINT,
    amount DECIMAL(10,2),
    create_time TIMESTAMP
);

-- åˆ›å»º TiFlash å‰¯æœ¬ï¼ˆç”¨äºåˆ†ææŸ¥è¯¢ï¼‰
ALTER TABLE orders SET TIFLASH REPLICA 1;

-- æŸ¥çœ‹åŒæ­¥çŠ¶æ€
SELECT * FROM information_schema.tiflash_replica WHERE TABLE_NAME = 'orders';

-- ä½¿ç”¨ TiFlash æ‰§è¡Œåˆ†ææŸ¥è¯¢
SELECT /*+ USE_TIFLASH() */
    user_id,
    COUNT(*) as order_count,
    SUM(amount) as total_amount
FROM orders
WHERE create_time >= '2024-01-01'
GROUP BY user_id;
```

**Spring Boot æ•´åˆ TiDB**ï¼š
```yaml
spring:
  datasource:
    driver-class-name: com.mysql.cj.jdbc.Driver
    url: jdbc:mysql://localhost:4000/test?useSSL=false&serverTimezone=UTC
    username: root
    password: ""
```

TiDB å®Œå…¨å…¼å®¹ MySQL åè®®ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨ MySQL é©±åŠ¨ã€‚

---

## NoSQL æ•°æ®åº“å®æˆ˜

### MongoDB

**Docker éƒ¨ç½²**ï¼š
```bash
docker run -d \
    --name mongodb \
    -p 27017:27017 \
    -e MONGO_INITDB_ROOT_USERNAME=admin \
    -e MONGO_INITDB_ROOT_PASSWORD=password \
    -v /data/mongodb:/data/db \
    mongo:7
```

**Spring Data MongoDB**ï¼š
```java
// å®ä½“ç±»
@Document(collection = "products")
@Data
public class Product {

    @Id
    private String id;

    private String name;
    private String description;

    // åµŒå…¥æ–‡æ¡£
    @Embedded
    private PriceInfo priceInfo;

    // æ•°ç»„
    private List<String> tags;

    // åœ°ç†ä½ç½®
    private GeoJsonPoint location;
}

@Data
public class PriceInfo {
    private BigDecimal amount;
    private String currency;
}

// Repository
public interface ProductRepository extends MongoRepository<Product, String> {

    // JSONæŸ¥è¯¢
    @Query("{ 'priceInfo.amount': { $gte: ?0, $lte: ?1 } }")
    List<Product> findByPriceRange(BigDecimal min, BigDecimal max);

    // åœ°ç†ä½ç½®æŸ¥è¯¢
    @Query("{ 'location': { $near: { $geometry: { 'type': 'Point', 'coordinates': [?0, ?1] }, $maxDistance: ?2 } } }")
    List<Product> findByLocationNear(double longitude, double latitude, double maxDistance);

    // å…¨æ–‡æœç´¢
    @Text
    List<Product> findByNameContaining(String keyword);
}

// Service
@Service
public class ProductService {

    @Autowired
    private ProductRepository productRepository;

    // èšåˆæŸ¥è¯¢
    public List<ProductStats> getSalesByCategory() {
        Aggregation aggregation = Aggregation.newAggregation(
            Aggregation.match(Criteria.where("tags").in("electronics")),
            Aggregation.group("category")
                .count().as("productCount")
                .sum("priceInfo.amount").as("totalRevenue"),
            Aggregation.sort(Sort.Direction.DESC, "totalRevenue"),
            Aggregation.limit(10)
        );

        return mongoTemplate.aggregate(aggregation, Product.class, ProductStats.class)
            .getMappedResults();
    }
}
```

### Redis é«˜çº§ç”¨æ³•

**Redisson åˆ†å¸ƒå¼é”**ï¼š
```java
@Configuration
public class RedisConfig {

    @Bean
    public RedissonClient redissonClient() {
        Config config = new Config();
        config.useSingleServer()
            .setAddress("redis://localhost:6379")
            .setPassword("password")
            .setDatabase(0);
        return Redisson.create(config);
    }
}

@Service
public class OrderService {

    @Autowired
    private RedissonClient redissonClient;

    public void createOrder(OrderDTO orderDTO) {
        // è·å–åˆ†å¸ƒå¼é”
        RLock lock = redissonClient.getLock("order:lock:" + orderDTO.getUserId());

        try {
            // å°è¯•åŠ é”ï¼Œæœ€å¤šç­‰å¾…10ç§’ï¼Œé”30ç§’åè‡ªåŠ¨é‡Šæ”¾
            if (lock.tryLock(10, 30, TimeUnit.SECONDS)) {
                try {
                    // ä¸šåŠ¡é€»è¾‘
                    doCreateOrder(orderDTO);
                } finally {
                    lock.unlock();
                }
            } else {
                throw new BusinessException("ç³»ç»Ÿç¹å¿™ï¼Œè¯·ç¨åé‡è¯•");
            }
        } catch (InterruptedException e) {
            Thread.currentThread().interrupt();
            throw new BusinessException("ç³»ç»Ÿé”™è¯¯");
        }
    }

    // è¯»å†™é”
    public Product getProduct(Long id) {
        RReadWriteLock rwLock = redissonClient.getReadWriteLock("product:lock:" + id);
        rwLock.readLock().lock();
        try {
            return productRepository.findById(id);
        } finally {
            rwLock.readLock().unlock();
        }
    }

    // ä¿¡å·é‡ï¼ˆé™æµï¼‰
    @GetMapping("/api/hot-product")
    public Result getHotProduct(Long productId) {
        RSemaphore semaphore = redissonClient.getSemaphore("rate:limit:" + productId);
        // è®¾ç½®æœ€å¤š100ä¸ªå¹¶å‘
        semaphore.trySetPermits(100);

        try {
            if (semaphore.tryAcquire()) {
                try {
                    return Result.success(productService.getHotProduct(productId));
                } finally {
                    semaphore.release();
                }
            } else {
                return Result.error("è¯·æ±‚è¿‡äºé¢‘ç¹");
            }
        } catch (InterruptedException e) {
            return Result.error("ç³»ç»Ÿé”™è¯¯");
        }
    }

    // å¸ƒéš†è¿‡æ»¤å™¨
    @PostConstruct
    public void initBloomFilter() {
        RBloomFilter<Long> bloomFilter = redissonClient.getBloomFilter("product:bloom");
        bloomFilter.tryInit(100000L, 0.01);  // é¢„è®¡10ä¸‡æ¡æ•°æ®ï¼Œè¯¯åˆ¤ç‡1%

        // é¢„çƒ­ï¼šåŠ è½½æ‰€æœ‰å•†å“ID
        List<Long> allProductIds = productService.getAllProductIds();
        allProductIds.forEach(bloomFilter::add);
    }

    public Product getProductById(Long id) {
        RBloomFilter<Long> bloomFilter = redissonClient.getBloomFilter("product:bloom");

        // å¸ƒéš†è¿‡æ»¤å™¨åˆ¤æ–­
        if (!bloomFilter.contains(id)) {
            throw new NotFoundException("å•†å“ä¸å­˜åœ¨");
        }

        // æŸ¥è¯¢ç¼“å­˜
        String cacheKey = "product:" + id;
        Product product = (Product) redisTemplate.opsForValue().get(cacheKey);
        if (product != null) {
            return product;
        }

        // æŸ¥è¯¢æ•°æ®åº“
        product = productRepository.findById(id).orElse(null);
        if (product != null) {
            redisTemplate.opsForValue().set(cacheKey, product, 1, TimeUnit.HOURS);
        }

        return product;
    }
}
```

---

## æ—¶åºæ•°æ®åº“ä¸å‘é‡æ•°æ®åº“

### TDengine å®æˆ˜

**å®‰è£… TDengine**ï¼š
```bash
# Docker éƒ¨ç½²
docker run -d \
    --name tdengine \
    -p 6030:6030 -p 6041:6041 -p 6043-6049:6043-6049 \
    -e TAOS_FQDN=tdengine \
    tdengine/tdengine:3.0
```

**åˆ›å»ºè¶…çº§è¡¨**ï¼š
```sql
-- åˆ›å»ºæ•°æ®åº“
CREATE DATABASE IF NOT EXISTS iot_monitoring
KEEP 365;  -- ä¿ç•™365å¤©

USE iot_monitoring;

-- åˆ›å»ºè¶…çº§è¡¨
CREATE STABLE sensors (
    ts TIMESTAMP,           -- æ—¶é—´æˆ³ï¼ˆå¿…é¡»ï¼‰
    temperature FLOAT,      -- æ¸©åº¦
    humidity FLOAT,         -- æ¹¿åº¦
    pressure FLOAT          -- å‹åŠ›
) TAGS (
    location BINARY(50),    -- ä½ç½®æ ‡ç­¾
    device_type BINARY(20)  -- è®¾å¤‡ç±»å‹æ ‡ç­¾
);

-- è‡ªåŠ¨åˆ›å»ºå­è¡¨å¹¶æ’å…¥æ•°æ®
INSERT INTO device_001 USING sensors TAGS ('åŒ—äº¬', 'æ¸©åº¦ä¼ æ„Ÿå™¨')
VALUES (NOW, 25.5, 60.2, 1013.25);

-- æŸ¥è¯¢æ•°æ®
SELECT * FROM sensors WHERE location = 'åŒ—äº¬';
SELECT AVG(temperature), AVG(humidity)
FROM sensors
WHERE ts > NOW - 1h
GROUP BY location;
```

---

## æ•°æ®åº“é€‰å‹ä¸æ¶æ„è®¾è®¡

### é€‰å‹å†³ç­–æ ‘

```mermaid
graph TD
    A[ä¸šåŠ¡éœ€æ±‚åˆ†æ] --> B{æ•°æ®é‡}
    B -->|< 100GB| C[å•æœºæ•°æ®åº“]
    B -->|100GB-10TB| D[åˆ†å¸ƒå¼æ•°æ®åº“]
    B -->|> 10TB| E[å¤§æ•°æ®å¹³å°]

    C --> C1{æŸ¥è¯¢ç±»å‹}
    C1 -->|OLTP| C2[MySQL/PostgreSQL]
    C1 -->|OLAP| C3[ClickHouse]

    D --> D1{ä¸€è‡´æ€§è¦æ±‚}
    D1 -->|å¼ºä¸€è‡´| D2[OceanBase/GaussDB]
    D1 -->|æœ€ç»ˆä¸€è‡´| D3[TiDB/TDSQL]

    E --> E1[æ•°æ®æ¹–/Hadoop]
```

---

## å®æˆ˜é¡¹ç›®

### é¡¹ç›®1ï¼šç”µå•†è®¢å•ç³»ç»Ÿæ•°æ®åº“è®¾è®¡

```sql
-- ç”¨æˆ·è¡¨
CREATE TABLE users (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    username VARCHAR(50) UNIQUE NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    password_hash VARCHAR(255) NOT NULL,
    status TINYINT DEFAULT 1 COMMENT '1:æ­£å¸¸ 0:ç¦ç”¨',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    INDEX idx_status (status),
    INDEX idx_created (created_at)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;

-- å•†å“è¡¨
CREATE TABLE products (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    name VARCHAR(200) NOT NULL,
    description TEXT,
    category_id INT NOT NULL,
    price DECIMAL(10,2) NOT NULL,
    stock INT DEFAULT 0,
    status TINYINT DEFAULT 1,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    INDEX idx_category (category_id),
    INDEX idx_status (status)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;

-- è®¢å•è¡¨ï¼ˆåˆ†è¡¨ï¼‰
CREATE TABLE orders_2024_01 (
    order_id BIGINT PRIMARY KEY,
    user_id BIGINT NOT NULL,
    total_amount DECIMAL(10,2) NOT NULL,
    status VARCHAR(32) NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    INDEX idx_user (user_id),
    INDEX idx_status (status),
    INDEX idx_created (created_at)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
PARTITION BY RANGE (TO_DAYS(created_at)) (
    PARTITION p20240101 VALUES LESS THAN (TO_DAYS('2024-01-15')),
    PARTITION p20240115 VALUES LESS THAN (TO_DAYS('2024-02-01')),
    PARTITION pmax VALUES LESS THAN MAXVALUE
);
```

---

**æ›´æ–°æ—¶é—´**ï¼š2026å¹´2æœˆ | **ç‰ˆæœ¬**ï¼šv1.0
