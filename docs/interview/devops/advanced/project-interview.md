---
title: DevOpsé«˜çº§é¢è¯•é¢˜ - å®æˆ˜é¡¹ç›®é¢è¯•é¢˜
---

# DevOpsé«˜çº§é¢è¯•é¢˜ - å®æˆ˜é¡¹ç›®é¢è¯•é¢˜

## é¡¹ç›®ä¸€ï¼šKuberneteså¤šé›†ç¾¤ç®¡ç†ç³»ç»Ÿ

### Q1: å¦‚ä½•å®ç°å¤šé›†ç¾¤ç»Ÿä¸€ç®¡ç†å’Œè®¤è¯ï¼Ÿ

**å‚è€ƒç­”æ¡ˆ**ï¼š

å¤šé›†ç¾¤ç®¡ç†çš„æ ¸å¿ƒæ˜¯ç»Ÿä¸€çš„APIè®¿é—®å’Œè®¤è¯æœºåˆ¶ã€‚

**1. é›†ç¾¤æ³¨å†Œå’Œè®¤è¯**

```go
// backend/services/cluster_service.go
type ClusterService struct {
    clusterRepo repositories.ClusterRepository
    clients     map[string]*kubernetes.Clientset
}

// æ³¨å†Œæ–°é›†ç¾¤
func (s *ClusterService) RegisterCluster(
    ctx context.Context,
    req models.RegisterClusterRequest,
) (*models.Cluster, error) {
    // 1. éªŒè¯kubeconfig
    config, err := clientcmd.RESTConfigFromKubeConfig(
        []byte(req.KubeConfig),
    )
    if err != nil {
        return nil, fmt.Errorf("invalid kubeconfig: %w", err)
    }

    // 2. åˆ›å»ºclientsetæµ‹è¯•è¿æ¥
    clientset, err := kubernetes.NewForConfig(config)
    if err != nil {
        return nil, fmt.Errorf("failed to create clientset: %w", err)
    }

    // 3. è·å–é›†ç¾¤ä¿¡æ¯
    version, err := clientset.Discovery().ServerVersion()
    if err != nil {
        return nil, fmt.Errorf("failed to get version: %w", err)
    }

    // 4. ä¿å­˜é›†ç¾¤ä¿¡æ¯
    cluster := &models.Cluster{
        ID:          xid.New().String(),
        Name:        req.Name,
        Environment: req.Environment,
        KubeConfig:  req.KubeConfig,  // åŠ å¯†å­˜å‚¨
        Version:     version.GitVersion,
        Status:      "active",
    }

    // 5. ç¼“å­˜clientset
    s.clients[cluster.ID] = clientset

    return cluster, nil
}
```

**2. ä½¿ç”¨kubeconfigè®¤è¯çš„æœ€ä½³å®è·µ**

```yaml
# æ¨èçš„RBACé…ç½®
apiVersion: v1
kind: ServiceAccount
metadata:
  name: multi-cluster-manager
  namespace: kube-system

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: multi-cluster-manager
rules:
  - apiGroups: [""]
    resources: ["nodes", "pods", "namespaces"]
    verbs: ["get", "list", "watch"]
  - apiGroups: ["apps"]
    resources: ["deployments", "replicasets"]
    verbs: ["get", "list", "watch", "create", "update", "patch"]
  - apiGroups: ["metrics.k8s.io"]
    resources: ["nodes", "pods"]
    verbs: ["get", "list"]

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: multi-cluster-manager
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: multi-cluster-manager
subjects:
  - kind: ServiceAccount
    name: multi-cluster-manager
    namespace: kube-system
```

**3. é›†ç¾¤è¿æ¥æ± ç®¡ç†**

```go
// è¿æ¥æ± å®ç°
type ClusterPool struct {
    sync.RWMutex
    clients map[string]*ClusterClient
    config  *PoolConfig
}

type ClusterClient struct {
    Clientset  *kubernetes.Clientset
    RESTConfig *rest.Config
    LastUsed   time.Time
}

// è·å–æˆ–åˆ›å»ºå®¢æˆ·ç«¯
func (p *ClusterPool) GetClient(clusterID string) (*ClusterClient, error) {
    p.RLock()
    client, exists := p.clients[clusterID]
    p.RUnlock()

    if exists {
        client.LastUsed = time.Now()
        return client, nil
    }

    // ä»æ•°æ®åº“åŠ è½½kubeconfig
    cluster, err := p.repo.FindByID(clusterID)
    if err != nil {
        return nil, err
    }

    // åˆ›å»ºæ–°å®¢æˆ·ç«¯
    config, _ := clientcmd.RESTConfigFromKubeConfig(
        []byte(cluster.KubeConfig),
    )
    clientset, _ := kubernetes.NewForConfig(config)

    newClient := &ClusterClient{
        Clientset:  clientset,
        RESTConfig: config,
        LastUsed:   time.Now(),
    }

    p.Lock()
    p.clients[clusterID] = newClient
    p.Unlock()

    return newClient, nil
}
```

**æ¶æ„è®¾è®¡è¦ç‚¹**ï¼š
- **å®‰å…¨æ€§**ï¼škubeconfigåŠ å¯†å­˜å‚¨ï¼ˆAES-256ï¼‰
- **é«˜å¯ç”¨**ï¼šå®¢æˆ·ç«¯è¿æ¥æ± ï¼Œé¿å…é¢‘ç¹åˆ›å»º
- **æƒé™æ§åˆ¶**ï¼šæœ€å°æƒé™åŸåˆ™ï¼ŒRBACç»†ç²’åº¦æ§åˆ¶
- **è¿æ¥å¤ç”¨**ï¼šä½¿ç”¨è¿æ¥æ± å‡å°‘èµ„æºæ¶ˆè€—

---

### Q2: å¦‚ä½•å®ç°è·¨é›†ç¾¤åº”ç”¨éƒ¨ç½²å’ŒåŒæ­¥ï¼Ÿ

**å‚è€ƒç­”æ¡ˆ**ï¼š

ä½¿ç”¨Helm + Argo CDå®ç°å£°æ˜å¼åº”ç”¨éƒ¨ç½²ã€‚

**1. Helm Chartéƒ¨ç½²**

```go
// backend/services/helm_service.go
type HelmService struct {
    actionConfigs map[string]*action.Configuration
}

// å®‰è£…Chartåˆ°å¤šä¸ªé›†ç¾¤
func (s *HelmService) InstallChart(
    ctx context.Context,
    req *models.InstallChartRequest,
) (*release.Release, error) {
    // è·å–é›†ç¾¤é…ç½®
    actionConfig, ok := s.actionConfigs[req.ClusterID]
    if !ok {
        return nil, fmt.Errorf("cluster not found")
    }

    // åˆ›å»ºå®‰è£…action
    install := action.NewInstall(actionConfig)
    install.ReleaseName = req.ReleaseName
    install.Namespace = req.Namespace
    install.CreateNamespace = true
    install.Wait = true
    install.Timeout = 5 * time.Minute

    // åŠ è½½Chart
    chart, err := loader.Load(req.ChartPath)
    if err != nil {
        return nil, fmt.Errorf("failed to load chart: %w", err)
    }

    // è§£ævalues
    values := make(map[string]interface{})
    if req.Values != "" {
        yaml.Unmarshal([]byte(req.Values), &values)
    }

    // æ‰§è¡Œå®‰è£…
    rel, err := install.RunWithContext(ctx, chart, values)
    if err != nil {
        return nil, fmt.Errorf("failed to install: %w", err)
    }

    return rel, nil
}
```

**2. Argo CDå¤šé›†ç¾¤éƒ¨ç½²**

```yaml
# infrastructure/argocd/applications/multi-cluster.yaml
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: multi-cluster-app
  namespace: argocd
spec:
  project: default

  source:
    repoURL: https://github.com/myorg/app.git
    targetRevision: main
    path: helm/my-app

  syncPolicy:
    automated:
      prune: true
      selfHeal: true
      allowEmpty: false

---

# éƒ¨ç½²åˆ°å¼€å‘é›†ç¾¤
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: app-dev
  namespace: argocd
spec:
  destination:
    server: https://dev-cluster.example.com
    namespace: production
  source:
    repoURL: https://github.com/myorg/app.git
    targetRevision: main
    path: helm/my-app
    helm:
      valueFiles:
        - values-dev.yaml

---

# éƒ¨ç½²åˆ°ç”Ÿäº§é›†ç¾¤
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: app-prod
  namespace: argocd
spec:
  destination:
    server: https://prod-cluster.example.com
    namespace: production
  source:
    repoURL: https://github.com/myorg/app.git
    targetRevision: main
    path: helm/my-app
    helm:
      valueFiles:
        - values-prod.yaml
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - CreateNamespace=true
```

**3. App of Appsæ¨¡å¼ï¼ˆåº”ç”¨ç¼–æ’ï¼‰**

```yaml
# infrastructure/argocd/apps-of-apps.yaml
apiVersion: argoproj.io/v1alpha1
kind: ApplicationSet
metadata:
  name: cluster-apps
  namespace: argocd
spec:
  generators:
    - clusters: {}  # è‡ªåŠ¨å‘ç°æ‰€æœ‰é›†ç¾¤

  template:
    metadata:
      name: '{{name}}-apps'
    spec:
      project: default
      source:
        repoURL: https://github.com/myorg/apps.git
        targetRevision: main
        path: apps/
      destination:
        server: '{{server}}'
        namespace: argocd
      syncPolicy:
        automated:
          prune: true
          selfHeal: true
```

**æœ€ä½³å®è·µ**ï¼š
- **GitOps**ï¼šæ‰€æœ‰é…ç½®å­˜å‚¨åœ¨Gitä¸­
- **å£°æ˜å¼**ï¼šä½¿ç”¨Helm/Kustomizeå£°æ˜åº”ç”¨çŠ¶æ€
- **è‡ªåŠ¨åŒæ­¥**ï¼šGitå˜æ›´è‡ªåŠ¨è§¦å‘éƒ¨ç½²
- **æ¸è¿›å¼äº¤ä»˜**ï¼šå…ˆéƒ¨ç½²åˆ°devï¼Œå†promoteåˆ°prod

---

### Q3: å¦‚ä½•å®ç°å¤šé›†ç¾¤ç›‘æ§å‘Šè­¦ï¼Ÿ

**å‚è€ƒç­”æ¡ˆ**ï¼š

ä½¿ç”¨Prometheusè”é‚¦æ¨¡å¼ + Thanoså®ç°å¤šé›†ç¾¤ç›‘æ§ã€‚

**1. Prometheusè”é‚¦é…ç½®**

```yaml
# monitoring/prometheus/federate-config.yml
scrape_configs:
  # ä»å„ä¸ªé›†ç¾¤é‡‡é›†æ•°æ®
  - job_name: 'federate-cluster-dev'
    honor_labels: true
    metrics_path: '/federate'
    params:
      'match[]':
        - '{__name__=~".*"}'
    static_configs:
      - targets:
          - prometheus-dev.monitoring.svc.cluster.local:9090

  - job_name: 'federate-cluster-prod'
    honor_labels: true
    metrics_path: '/federate'
    params:
      'match[]':
        - '{__name__=~".*"}'
    static_configs:
      - targets:
          - prometheus-prod.monitoring.svc.cluster.local:9090

  # é«˜ä»·å€¼æŒ‡æ ‡å®Œæ•´é‡‡é›†
  - job_name: 'critical-metrics-dev'
    honor_labels: true
    metrics_path: '/federate'
    params:
      'match[]':
        - '{__name__=~"kube_.*"}'
        - '{__name__=~"container_.*"}'
        - '{__name__=~"node_.*"}'
    static_configs:
      - targets:
          - prometheus-dev.monitoring.svc.cluster.local:9090
```

**2. Thanoså…¨å±€è§†å›¾æ¶æ„**

```yaml
# infrastructure/thanos/thanos-query-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: thanos-query
  namespace: monitoring
spec:
  replicas: 2
  selector:
    matchLabels:
      app: thanos-query
  template:
    metadata:
      labels:
        app: thanos-query
    spec:
      containers:
        - name: thanos-query
          image: quay.io/thanos/thanos:v0.32.4
          args:
            - query
            - --query.replica-label=replica
            - --store=dnssrv+grpc://thanos-store-dev.thanos.svc.cluster.local:10901
            - --store=dnssrv+grpc://thanos-store-prod.thanos.svc.cluster.local:10901
          ports:
            - containerPort: 10902
              name: http
            - containerPort: 10901
              name: grpc

---
apiVersion: v1
kind: Service
metadata:
  name: thanos-query
  namespace: monitoring
spec:
  selector:
    app: thanos-query
  ports:
    - port: 9090
      targetPort: http
  type: LoadBalancer
```

**3. è·¨é›†ç¾¤å‘Šè­¦è§„åˆ™**

```yaml
# monitoring/prometheus/rules/multi-cluster-alerts.yml
groups:
  - name: multi_cluster_alerts
    interval: 30s
    rules:
      # è·¨é›†ç¾¤å¯¹æ¯”å‘Šè­¦
      - alert: HighErrorRateComparedToPeers
        expr: |
          sum(rate(http_requests_total{status=~"5.."}[5m])) by (cluster)
          /
          sum(rate(http_requests_total[5m])) by (cluster)
          > 0.05
          and
          sum(rate(http_requests_total{status=~"5.."}[5m])) by (cluster)
          /
          sum(rate(http_requests_total[5m])) by (cluster)
          > avg(
            sum(rate(http_requests_total{status=~"5.."}[5m])) by (cluster)
            /
            sum(rate(http_requests_total[5m])) by (cluster)
          ) * 2
        for: 10m
        labels:
          severity: warning
          scope: multi-cluster
        annotations:
          summary: "Cluster {{ $labels.cluster }} error rate is 2x higher than average"
          description: "Error rate {{ $value | humanizePercentage }} on {{ $labels.cluster }}"

      # é›†ç¾¤å¥åº·åº¦è¯„åˆ†
      - alert: ClusterHealthDegraded
        expr: |
          (
            avg(kube_node_status_condition{condition="Ready",status="true"}) by (cluster)
            * avg(rate(container_cpu_usage_seconds_total[5m]) < 0.8) by (cluster)
            * avg(container_memory_working_set_bytes / container_spec_memory_limit_bytes < 0.9) by (cluster)
          ) < 0.7
        for: 15m
        labels:
          severity: critical
        annotations:
          summary: "Cluster {{ $labels.cluster }} health degraded"
```

**Grafanaå¤šé›†ç¾¤ä»ªè¡¨ç›˜é…ç½®**ï¼š

```json
{
  "dashboard": {
    "title": "Multi-Cluster Overview",
    "panels": [
      {
        "title": "Cluster Health Score",
        "type": "stat",
        "targets": [
          {
            "expr": "avg(kube_node_status_condition{condition=\"Ready\",status=\"true\"}) by (cluster)"
          }
        ]
      },
      {
        "title": "Cross-Cluster Error Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "sum(rate(http_requests_total{status=~\"5..\"}[5m])) by (cluster) / sum(rate(http_requests_total[5m])) by (cluster)"
          }
        ]
      }
    ]
  }
}
```

**å…³é”®ç‚¹**ï¼š
- **è”é‚¦æ¨¡å¼**ï¼šä¸­å¤®Prometheusé‡‡é›†å„é›†ç¾¤æ•°æ®
- **Thanos**ï¼šæä¾›å…¨å±€æŸ¥è¯¢å’Œé•¿æœŸå­˜å‚¨
- **æ ‡ç­¾è§„èŒƒåŒ–**ï¼šç»Ÿä¸€clusteræ ‡ç­¾ä¾¿äºèšåˆ
- **æ™ºèƒ½å‘Šè­¦**ï¼šè·¨é›†ç¾¤å¯¹æ¯”ï¼Œå‡å°‘è¯¯æŠ¥

---

## é¡¹ç›®äºŒï¼šPlatform Engineering - å†…éƒ¨å¼€å‘è€…å¹³å°

### Q4: å¦‚ä½•è®¾è®¡BackstageæœåŠ¡ç›®å½•å’Œå¾®æœåŠ¡æ³¨å†Œï¼Ÿ

**å‚è€ƒç­”æ¡ˆ**ï¼š

æœåŠ¡ç›®å½•æ˜¯IDPçš„æ ¸å¿ƒï¼Œç”¨äºè‡ªåŠ¨å‘ç°å’Œæ³¨å†Œæ‰€æœ‰æœåŠ¡ã€‚

**1. BackstageæœåŠ¡ç›®å½•é…ç½®**

```yaml
# backstage/app-config.yaml
catalog:
  import:
    entityFilename: catalog-info.yaml
    pullRequestBranchName: backstage-integration
  rules:
    - allow: [Component, System, API, Resource, Location, Template]
  locations:
    # æ‰«æGitHubç»„ç»‡çš„æ‰€æœ‰æœåŠ¡
    - type: url
      target: https://github.com/myorg/all-services/blob/master/catalog-info.yaml

    # æ‰«æç‰¹å®šä»“åº“
    - type: github-org
      target: https://github.com/myorg
      catalogPath: /catalog-info.yaml

    # æœ¬åœ°æ¨¡æ¿
    - type: file
      target: ./catalog-info.yaml
      rules:
        - allow: [Template]
```

**2. å¾®æœåŠ¡catalog-info.yamlç¤ºä¾‹**

```yaml
# user-service/catalog-info.yaml
apiVersion: backstage.io/v1alpha1
kind: Component
metadata:
  name: user-service
  description: User management service with authentication
  tags:
    - microservice
    - python
    - fastapi
    - authentication
  annotations:
    github.com/project-slug: myorg/user-service
    argocd/app-name: user-service
    prometheus.io/port: '5001'
    prometheus.io/scrape: 'true'
    backstage.io/techdocs-ref: dir:.
spec:
  type: service
  lifecycle: production
  owner: backend-team
  system: ecommerce-system

  # ä¾èµ–å…³ç³»
  dependsOn:
    - resource:postgres
    - resource:redis
    - service:auth-service

  # æä¾›çš„API
  providesApis:
    - user-api

  # ä½¿ç”¨çš„API
  consumesApis:
    - auth-api

  # é‡è¦ç¨‹åº¦
  importance: critical

  # ç›‘æ§é“¾æ¥
  links:
    - url: https://grafana.example.com/d/user-service
      title: Grafana Dashboard
      icon: dashboard
    - url: https://argocd.example.com/applications/user-service
      title: Argo CD
      icon: cloud
    - url: https://alerts.example.com/user-service
      title: Alerts
      icon: alarm
```

**3. ç³»ç»Ÿçº§catalogé…ç½®**

```yaml
# ecommerce-system/catalog-info.yaml
apiVersion: backstage.io/v1alpha1
kind: System
metadata:
  name: ecommerce-system
  description: E-commerce platform
  tags:
    - ecommerce
    - microservices
spec:
  owner: platform-team
  domain: business-platform

# ç”¨æˆ·APIå®šä¹‰
---
apiVersion: backstage.io/v1alpha1
kind: API
metadata:
  name: user-api
  description: User management API
  tags:
    - rest
    - grpc
spec:
  type: openapi
  lifecycle: production
  owner: backend-team
  system: ecommerce-system
  definition:
    $text: ./openapi.yaml
```

**4. è‡ªåŠ¨æœåŠ¡æ³¨å†Œï¼ˆGitHub Actionsï¼‰**

```yaml
# .github/workflows/register-service.yml
name: Register Service in Catalog

on:
  push:
    paths:
      - 'catalog-info.yaml'

jobs:
  register:
    runs-on: ubuntu-latest
    steps:
      - name: Validate catalog-info.yaml
        uses: backstage/backstage-master/issues/354

      - name: Update service index
        run: |
          # æ›´æ–°all-servicesä»“åº“
          git clone https://github.com/myorg/all-services.git
          echo "- name: ${{ github.repository }}" >> all-services/services.yaml

      - name: Notify Backstage
        run: |
          curl -X POST http://backstage.example.com/api/catalog/refresh \
            -H "Authorization: Bearer ${{ secrets.BACKSTAGE_TOKEN }}"
```

**æ¶æ„è¦ç‚¹**ï¼š
- **è‡ªåŠ¨å‘ç°**ï¼šæ‰«æGitHubç»„ç»‡è‡ªåŠ¨æ³¨å†Œ
- **ä¾èµ–æ˜ å°„**ï¼šæ˜ç¡®å®šä¹‰æœåŠ¡ä¾èµ–å…³ç³»
- **ç”Ÿå‘½å‘¨æœŸç®¡ç†**ï¼šdev â†’ staging â†’ prod
- **æ‰€æœ‰æƒæ¸…æ™°**ï¼šæ˜ç¡®teamè´Ÿè´£
- **å¯è§‚æµ‹æ€§é›†æˆ**ï¼šé›†æˆç›‘æ§ã€æ—¥å¿—ã€è¿½è¸ª

---

### Q5: å¦‚ä½•å®ç°Golden Pathæ¨¡æ¿å’ŒæœåŠ¡è„šæ‰‹æ¶ï¼Ÿ

**å‚è€ƒç­”æ¡ˆ**ï¼š

Golden Pathæ˜¯ç»è¿‡éªŒè¯çš„æœ€ä½³å®è·µè·¯å¾„ï¼Œè®©å¼€å‘è€…å¿«é€Ÿåˆ›å»ºç”Ÿäº§å°±ç»ªçš„æœåŠ¡ã€‚

**1. Backstage Templateé…ç½®**

```yaml
# backstage/templates/golden-path/template.yaml
apiVersion: backstage.io/v1alpha1
kind: Template
metadata:
  name: golden-path-microservice
  title: Golden Path - Microservice
  description: Production-ready microservice template
  tags:
    - microservice
    - kubernetes
    - recommended

spec:
  type: service
  owner: platform-team
  lifecycle: production

  parameters:
    - title: Service Information
      required: ['serviceName', 'owner']
      properties:
        serviceName:
          title: Service Name
          type: string
          description: Unique service name (kebab-case)
          pattern: ^[a-z0-9-]+$
          ui:autofocus: true
        owner:
          title: Owner Team
          type: string
          description: Team responsible for this service
          ui:field: OwnerPicker
        description:
          title: Description
          type: string
          description: What does this service do?

    - title: Choose a Location
      required: ['repoUrl']
      properties:
        repoUrl:
          title: Repository Location
          type: string
          ui:field: RepoUrlPicker
          ui:options:
            allowedHosts:
              - github.com

    - title: Technology Stack
      required: ['language', 'framework']
      properties:
        language:
          title: Language
          type: string
          enum: ['Python', 'Node.js', 'Go', 'Java']
          default: Python
        framework:
          title: Framework
          type: string
          enum: ['FastAPI', 'Flask', 'Express', 'Gin', 'Spring Boot']
        database:
          title: Database
          type: string
          enum: ['PostgreSQL', 'MySQL', 'MongoDB', 'None']
          default: PostgreSQL

    - title: Deployment Configuration
      properties:
        replicas:
          title: Replicas
          type: number
          default: 2
        cpu:
          title: CPU (m)
          type: number
          default: 100
        memory:
          title: Memory (Mi)
          type: number
          default: 128

  # å·¥ä½œæµæ­¥éª¤
  steps:
    - id: scaffold
      name: Scaffold Project
      action: scaffold:cookiecutter
      input:
        url: ./templates/microservice
        values:
          name: ${{ parameters.serviceName }}
          description: ${{ parameters.description }}
          language: ${{ parameters.language }}
          framework: ${{ parameters.framework }}
          database: ${{ parameters.database }}

    - id: create-repo
      name: Create Repository
      action: publish:github
      input:
        repoUrl: ${{ parameters.repoUrl }}
        description: 'Service ${{ parameters.serviceName }}'
        topics:
          - microservice
          - golden-path
          - backstage

    - id: register-catalog
      name: Register in Catalog
      action: catalog:register
      input:
        repoContentsUrl: ${{ steps['create-repo'].output.repoContentsUrl }}
        catalogInfoPath: '/catalog-info.yaml'

    - id: deploy-staging
      name: Deploy to Staging
      action: argocd:create
      input:
        appName: ${{ parameters.serviceName }}
        repoUrl: ${{ steps['create-repo'].output.repoUrl }}
        namespace: staging
        values:
          replicas: ${{ parameters.replicas }}

    - id: setup-monitoring
      name: Setup Monitoring
      action: prometheus:setup
      input:
        service: ${{ parameters.serviceName }}
        namespace: staging
        enableAlerts: true

  output:
    links:
      - title: Repository
        url: ${{ steps['create-repo'].output.remoteUrl }}
        icon: github
      - title: Open in catalog
        icon: catalog
        entityRef: ${{ steps['register-catalog'].output.entityRef }}
      - title: Argo CD Application
        url: https://argocd.example.com/applications/${{ parameters.serviceName }}
        icon: cloud
      - title: Grafana Dashboard
        url: https://grafana.example.com/d/${{ parameters.serviceName }}
        icon: dashboard
```

**2. Cookiecutteræ¨¡æ¿**

```jinja2
# templates/microservice/{{cookiecutter.name}}/Dockerfile
FROM python:3.11-slim

WORKDIR /app

# å®‰è£…ä¾èµ–
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# å¤åˆ¶ä»£ç 
COPY . .

# érootç”¨æˆ·è¿è¡Œ
USER nobody

EXPOSE 8000

CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

```jinja2
# templates/microservice/{{cookiecutter.name}}/Chart.yaml
apiVersion: v2
name: {{cookiecutter.name}}
description: A Helm chart for {{cookiecutter.name}}
type: application
version: 0.1.0
appVersion: "1.0"

# templates/microservice/{{cookiecutter.name}}/values.yaml
replicaCount: {{cookiecutter.replicas}}

image:
  repository: myorg/{{cookiecutter.name}}
  tag: latest
  pullPolicy: IfNotPresent

service:
  type: ClusterIP
  port: {{cookiecutter.port}}

resources:
  limits:
    cpu: {{cookiecutter.cpu}}m
    memory: {{cookiecutter.memory}}Mi
  requests:
    cpu: {{cookiecutter.cpu}}m
    memory: {{cookiecutter.memory}}Mi

autoscaling:
  enabled: true
  minReplicas: {{cookiecutter.replicas}}
  maxReplicas: 10
  targetCPUUtilizationPercentage: 80
  targetMemoryUtilizationPercentage: 80

# database
{% if cookiecutter.database != 'None' %}
{{cookiecutter.database.lower()}}:
  enabled: true
  auth:
    database: {{cookiecutter.name.replace('-', '_')}}
    username: {{cookiecutter.name}}
{% endif %}
```

**3. è¯„åˆ†å¡ï¼ˆScorecardï¼‰éªŒè¯**

```yaml
# .github/scorecard.yml
apiVersion: scorecard.dev/v1alpha1
kind: ScorecardConfig

checks:
  - id: deployment-exists
    name: Deployment exists
    description: Check if Kubernetes deployment exists
    type: kubernetes
    resource: deployment
    weight: 10

  - id: service-exists
    name: Service exists
    type: kubernetes
    resource: service
    weight: 10

  - id: monitoring-enabled
    name: Monitoring enabled
    description: Check if ServiceMonitor exists
    type: kubernetes
    resource: servicemonitor
    weight: 15

  - id: has-docs
    name: Has documentation
    type: file
    pattern: README.md
    weight: 10

  - id: has-tests
    name: Has tests
    type: file
    pattern: "**/*test*.py"
    weight: 15

  - id: helm-chart-exists
    name: Helm chart exists
    type: file
    pattern: "helm/**/Chart.yaml"
    weight: 10

  - id: security-scan-passed
    name: Security scan passed
    type: security
    scanner: trivy
    weight: 15

scorecard:
  passing: 70  # 70åˆ†ä»¥ä¸Šæ‰ç®—é€šè¿‡
```

**å…³é”®ç‚¹**ï¼š
- **æ ‡å‡†åŒ–**ï¼šç»Ÿä¸€çš„ç›®å½•ç»“æ„å’Œé…ç½®
- **è‡ªåŠ¨åŒ–**ï¼šä¸€é”®åˆ›å»ºä»“åº“ã€éƒ¨ç½²ã€ç›‘æ§
- **æœ€ä½³å®è·µ**ï¼šå†…ç½®å®‰å…¨å’Œè´¨é‡æ£€æŸ¥
- **å¯æ‰©å±•**ï¼šæ”¯æŒå¤šç§è¯­è¨€å’Œæ¡†æ¶
- **è¯„åˆ†æœºåˆ¶**ï¼šç¡®ä¿æœåŠ¡è´¨é‡

---

### Q6: å¦‚ä½•å®ç°Backstageæ’ä»¶å¼€å‘å’Œæ‰©å±•ï¼Ÿ

**å‚è€ƒç­”æ¡ˆ**ï¼š

Backstageæ’ä»¶æ˜¯æ‰©å±•å¹³å°èƒ½åŠ›çš„æ ¸å¿ƒæœºåˆ¶ã€‚

**1. è‡ªå®šä¹‰æ’ä»¶ç»“æ„**

```typescript
// backstage/plugins/service-template/src/plugin.ts
import {
  createPlugin,
  createRoutableExtension,
  discoveryApiRef,
  fetchApiRef,
} from '@backstage/core-plugin-api';

export const serviceTemplatePlugin = createPlugin({
  id: 'service-template',
  apis: [],  // å¯ä»¥å®šä¹‰API
});

export const ServiceTemplatePage = serviceTemplatePlugin.provide(
  createRoutableExtension({
    name: 'ServiceTemplatePage',
    component: () => import('./components/TemplatePage'),
    mountPoint: rootRouteRef,
  }),
);
```

**2. æ’ä»¶APIé›†æˆ**

```typescript
// backstage/plugins/deployment/src/api/index.ts
import {
  createApiRef,
  discoveryApiRef,
  fetchApiRef,
} from '@backstage/core-plugin-api';

export const argocdApiRef = createApiRef<ArgoCDApi>({
  id: 'plugin.argocd.service',
});

export class ArgoCDApi {
  constructor(
    private readonly discoveryApi: DiscoveryApi,
    private readonly fetchApi: FetchApi,
  ) {}

  async getApplication(appName: string): Promise<Application> {
    const baseUrl = await this.discoveryApi.getBaseUrl('argocd');
    const response = await this.fetchApi.fetch(
      `${baseUrl}/api/v1/applications/${appName}`
    );
    return response.json();
  }

  async syncApplication(appName: string): Promise<void> {
    const baseUrl = await this.discoveryApi.getBaseUrl('argocd');
    await this.fetchApi.fetch(`${baseUrl}/api/v1/applications/${appName}/sync`, {
      method: 'POST',
    });
  }
}

// APIå·¥å‚
export const ArgoCDApiFactory = createApiFactory({
  api: argocdApiRef,
  deps: { discoveryApi: discoveryApiRef, fetchApi: fetchApiRef },
  factory: ({ discoveryApi, fetchApi }) =>
    new ArgoCDApi(discoveryApi, fetchApi),
});
```

**3. æ’ä»¶å‰ç«¯ç»„ä»¶**

```typescript
// backstage/plugins/cost-insights/src/components/CostDashboard.tsx
import React, { useState, useEffect } from 'react';
import {
  Table,
  TableColumn,
  Progress,
} from '@backstage/core-components';
import { useApi } from '@backstage/core-plugin-api';
import { costInsightsApiRef } from '../api';

export const CostDashboard = () => {
  const costApi = useApi(costInsightsApiRef);
  const [costs, setCosts] = useState([]);
  const [loading, setLoading] = useState(true);

  useEffect(() => {
    const fetchCosts = async () => {
      try {
        const data = await costApi.getCosts({
          groupBy: 'service',
          timeframe: 'last30days',
        });
        setCosts(data);
      } catch (err) {
        console.error(err);
      } finally {
        setLoading(false);
      }
    };

    fetchCosts();
  }, [costApi]);

  const columns: TableColumn[] = [
    { title: 'Service', field: 'service' },
    { title: 'Cost (USD)', field: 'cost', type: 'currency' },
    { title: 'Change %', field: 'change' },
    { title: 'Trend', field: 'trend' },
  ];

  if (loading) return <Progress />;

  return <Table columns={columns} data={costs} />;
};
```

**4. åç«¯æ’ä»¶**

```typescript
// backstage/plugins/catalog-backend-module-argocd/src/processor.ts
import {
  CatalogProcessor,
  CatalogProcessorEmit,
} from '@backstage/plugin-catalog-node';

export class ArgoCDProcessor implements CatalogProcessor {
  async postProcessEntity(
    entity: Entity,
    location: Location,
    emit: CatalogProcessorEmit,
  ): Promise<Entity> {
    if (entity.kind !== 'Component') {
      return entity;
    }

    const appName = entity.metadata.annotations?.['argocd/app-name'];
    if (!appName) {
      return entity;
    }

    // ä»Argo CDè·å–åº”ç”¨ä¿¡æ¯
    const argocdInfo = await this.fetchArgoCDInfo(appName);

    // æ›´æ–°entity
    emit({
      type: 'patch',
      patch: {
        ...entity,
        metadata: {
          ...entity.metadata,
          labels: {
            ...entity.metadata.labels,
            'argocd/app-status': argocdInfo.status.sync.status,
          },
        },
      },
    });

    return entity;
  }
}
```

**5. æ’ä»¶æ³¨å†Œ**

```typescript
// backstage/app/plugins.ts
export const plugins = [
  // æ ¸å¿ƒæ’ä»¶
  scaffolderPlugin,
  catalogPlugin,
  techdocsPlugin,

  // è‡ªå®šä¹‰æ’ä»¶
  serviceTemplatePlugin,
  deploymentPlugin,
  costInsightsPlugin,
  aiAssistantPlugin,
];

// APIæ³¨å†Œ
export const apis = [
  // ArgoCD API
  ArgoCDApiFactory,

  // è‡ªå®šä¹‰API
  costInsightsApiRef,
  aiAssistantApiRef,
];
```

**æ’ä»¶å¼€å‘æœ€ä½³å®è·µ**ï¼š
- **æ¨¡å—åŒ–**ï¼šå•ä¸€èŒè´£ï¼Œæ˜“äºç»´æŠ¤
- **APIä¼˜å…ˆ**ï¼šå®šä¹‰æ¸…æ™°çš„APIæ¥å£
- **ç±»å‹å®‰å…¨**ï¼šä½¿ç”¨TypeScript
- **å¯æµ‹è¯•**ï¼šç¼–å†™å•å…ƒæµ‹è¯•
- **æ–‡æ¡£åŒ–**ï¼šæä¾›ä½¿ç”¨æ–‡æ¡£å’Œç¤ºä¾‹

---

## é¡¹ç›®ä¸‰ï¼šAIOps - AIé©±åŠ¨çš„æ™ºèƒ½è¿ç»´ç³»ç»Ÿ

### Q7: å¦‚ä½•å®ç°å¼‚å¸¸æ£€æµ‹å’Œæ•…éšœé¢„æµ‹ï¼Ÿ

**å‚è€ƒç­”æ¡ˆ**ï¼š

ä½¿ç”¨æœºå™¨å­¦ä¹ ç®—æ³•å®ç°å¼‚å¸¸æ£€æµ‹å’Œæ•…éšœé¢„æµ‹ã€‚

**1. Isolation Forestå¼‚å¸¸æ£€æµ‹**

```python
# backend/app/services/anomaly_service.py
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import StandardScaler
import numpy as np

class AnomalyDetectionService:
    def __init__(self):
        self.scaler = StandardScaler()
        self.models = {}  # æ¯ä¸ªæœåŠ¡ä¸€ä¸ªæ¨¡å‹
        self.threshold = -0.5

    def train_model(self, service_name: str, metrics: np.ndarray):
        """è®­ç»ƒå¼‚å¸¸æ£€æµ‹æ¨¡å‹"""
        # æ ‡å‡†åŒ–æ•°æ®
        scaled_metrics = self.scaler.fit_transform(metrics)

        # è®­ç»ƒIsolation Forest
        model = IsolationForest(
            contamination=0.1,  # é¢„æœŸå¼‚å¸¸æ¯”ä¾‹
            random_state=42,
            n_estimators=100
        )
        model.fit(scaled_metrics)

        # ä¿å­˜æ¨¡å‹
        self.models[service_name] = model

    def detect_anomaly(
        self,
        service_name: str,
        current_metrics: Dict[str, float]
    ) -> Dict[str, Any]:
        """å®æ—¶å¼‚å¸¸æ£€æµ‹"""
        if service_name not in self.models:
            return {
                "status": "no_model",
                "message": "No trained model for this service"
            }

        model = self.models[service_name]

        # æå–ç‰¹å¾
        features = np.array([[
            current_metrics.get('cpu_usage', 0),
            current_metrics.get('memory_usage', 0),
            current_metrics.get('error_rate', 0),
            current_metrics.get('latency_p95', 0),
            current_metrics.get('request_rate', 0),
        ]])

        # æ ‡å‡†åŒ–
        scaled_features = self.scaler.transform(features)

        # é¢„æµ‹
        prediction = model.predict(scaled_features)[0]
        score = model.score_samples(scaled_features)[0]

        is_anomaly = prediction == -1 or score < self.threshold

        return {
            "service": service_name,
            "status": "anomaly" if is_anomaly else "normal",
            "anomaly_score": float(score),
            "metrics": current_metrics,
            "severity": self._calculate_severity(score)
        }

    def _calculate_severity(self, score: float) -> str:
        """è®¡ç®—å¼‚å¸¸ä¸¥é‡ç¨‹åº¦"""
        if score < -0.8:
            return "critical"
        elif score < -0.6:
            return "high"
        elif score < -0.4:
            return "medium"
        else:
            return "low"
```

**2. Prophetæ—¶é—´åºåˆ—é¢„æµ‹**

```python
# backend/app/services/prediction_service.py
from prophet import Prophet
import pandas as pd

class PredictionService:
    def __init__(self):
        self.models = {}

    def train_prediction_model(
        self,
        service_name: str,
        historical_data: pd.DataFrame
    ):
        """è®­ç»ƒPropheté¢„æµ‹æ¨¡å‹"""
        # Prophetæ ¼å¼ï¼šds (datetime), y (value)
        df = historical_data.rename(
            columns={'timestamp': 'ds', 'value': 'y'}
        )

        # åˆ›å»ºProphetæ¨¡å‹
        model = Prophet(
            yearly_seasonality=True,
            weekly_seasonality=True,
            daily_seasonality=True,
            interval_width=0.95
        )

        # è®­ç»ƒ
        model.fit(df)
        self.models[service_name] = model

    async def predict_capacity(
        self,
        service_name: str,
        hours: int = 24
    ) -> Dict[str, Any]:
        """é¢„æµ‹å®¹é‡éœ€æ±‚"""
        if service_name not in self.models:
            return {"error": "No trained model"}

        model = self.models[service_name]

        # åˆ›å»ºæœªæ¥æ—¶é—´ç‚¹
        future = model.make_future_dataframe(periods=hours, freq='H')

        # é¢„æµ‹
        forecast = model.predict(future)

        # æå–é¢„æµ‹ç»“æœ
        predictions = forecast.tail(hours)[
            ['ds', 'yhat', 'yhat_lower', 'yhat_upper']
        ]

        # è®¡ç®—æ¨èé…ç½®
        peak_demand = predictions['yhat'].max()
        avg_demand = predictions['yhat'].mean()

        return {
            "service": service_name,
            "predictions": predictions.to_dict('records'),
            "recommendations": {
                "peak_cpu": float(peak_demand),
                "avg_cpu": float(avg_demand),
                "recommended_replicas": self._calculate_replicas(peak_demand),
                "scale_up_threshold": float(peak_demand * 0.8),
            }
        }

    def _calculate_replicas(self, cpu_demand: float) -> int:
        """æ ¹æ®CPUéœ€æ±‚è®¡ç®—å‰¯æœ¬æ•°"""
        # æ¯ä¸ªå‰¯æœ¬èƒ½å¤„ç†50% CPU
        single_pod_capacity = 50
        replicas = int(np.ceil(cpu_demand / single_pod_capacity))
        return max(2, min(10, replicas))
```

**3. LSTMæ·±åº¦å­¦ä¹ é¢„æµ‹ï¼ˆé«˜çº§ï¼‰**

```python
# backend/app/services/lstm_prediction.py
import torch
import torch.nn as nn

class LSTMPredictor(nn.Module):
    def __init__(self, input_size=5, hidden_size=64, num_layers=2):
        super().__init__()
        self.lstm = nn.LSTM(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            batch_first=True,
            dropout=0.2
        )
        self.fc = nn.Linear(hidden_size, 1)

    def forward(self, x):
        lstm_out, _ = self.lstm(x)
        predictions = self.fc(lstm_out[:, -1, :])
        return predictions

class LSTMService:
    def __init__(self):
        self.model = LSTMPredictor()
        self.scaler = MinMaxScaler()

    def train(self, data: np.ndarray, epochs: int = 100):
        """è®­ç»ƒLSTMæ¨¡å‹"""
        # å‡†å¤‡æ•°æ®
        scaled_data = self.scaler.fit_transform(data)

        # åˆ›å»ºåºåˆ—
        X, y = self._create_sequences(scaled_data, lookback=24)

        # è®­ç»ƒ
        criterion = nn.MSELoss()
        optimizer = torch.optim.Adam(self.model.parameters(), lr=0.001)

        for epoch in range(epochs):
            self.model.train()
            optimizer.zero_grad()
            outputs = self.model(torch.FloatTensor(X))
            loss = criterion(outputs, torch.FloatTensor(y))
            loss.backward()
            optimizer.step()

    def predict(self, recent_data: np.ndarray) -> float:
        """é¢„æµ‹ä¸‹ä¸€ä¸ªæ—¶é—´ç‚¹"""
        self.model.eval()
        with torch.no_grad():
            scaled = self.scaler.transform(recent_data)
            x = scaled.reshape(1, -1, recent_data.shape[1])
            prediction = self.model(torch.FloatTensor(x))
            return self.scaler.inverse_transform(prediction.numpy())[0][0]

    def _create_sequences(self, data, lookback=24):
        X, y = [], []
        for i in range(len(data) - lookback):
            X.append(data[i:i+lookback])
            y.append(data[i+lookback])
        return np.array(X), np.array(y)
```

**å…³é”®ç‚¹**ï¼š
- **æ— ç›‘ç£å­¦ä¹ **ï¼šIsolation Forestæ— éœ€æ ‡ç­¾æ•°æ®
- **æ—¶é—´åºåˆ—**ï¼šProphetæ•æ‰å­£èŠ‚æ€§è¶‹åŠ¿
- **æ·±åº¦å­¦ä¹ **ï¼šLSTMå¤„ç†å¤æ‚æ¨¡å¼
- **ç‰¹å¾å·¥ç¨‹**ï¼šå¤šç»´åº¦æŒ‡æ ‡èåˆ
- **åœ¨çº¿å­¦ä¹ **ï¼šæŒç»­æ›´æ–°æ¨¡å‹

---

### Q8: å¦‚ä½•å®ç°AIè‡ªåŠ¨æ•…éšœè¯Šæ–­ï¼ˆRCAï¼‰ï¼Ÿ

**å‚è€ƒç­”æ¡ˆ**ï¼š

ä½¿ç”¨LLM + å·¥å…·è°ƒç”¨å®ç°æ™ºèƒ½æ•…éšœè¯Šæ–­ã€‚

**1. AI Agentæ¶æ„**

```python
# backend/app/services/ai_service.py
from langchain.agents import AgentExecutor, create_openai_functions_agent
from langchain.tools import Tool
from langchain_openai import ChatOpenAI

class AIService:
    def __init__(self):
        self.llm = ChatOpenAI(
            model="gpt-4-turbo-preview",
            temperature=0
        )
        self.tools = self._create_tools()
        self.agent = self._create_agent()

    def _create_tools(self) -> List[Tool]:
        """åˆ›å»ºè¯Šæ–­å·¥å…·é›†"""
        return [
            Tool(
                name="GetMetrics",
                func=self._get_metrics,
                description="è·å–PrometheusæŒ‡æ ‡ï¼Œæ ¼å¼ï¼šquery, time_range"
            ),
            Tool(
                name="QueryLogs",
                func=self._query_logs,
                description="æŸ¥è¯¢Elasticsearchæ—¥å¿—ï¼Œæ ¼å¼ï¼šquery, time_range"
            ),
            Tool(
                name="GetPodStatus",
                func=self._get_pod_status,
                description="è·å–PodçŠ¶æ€ï¼Œæ ¼å¼ï¼šnamespace, pod_name"
            ),
            Tool(
                name="GetEvents",
                func=self._get_events,
                description="è·å–Kubernetesäº‹ä»¶ï¼Œæ ¼å¼ï¼šnamespace"
            ),
            Tool(
                name="AnalyzeAnomaly",
                func=self._analyze_anomaly,
                description="åˆ†æå¼‚å¸¸æŒ‡æ ‡ï¼Œæ ¼å¼ï¼šservice_name"
            ),
        ]

    def _create_agent(self):
        """åˆ›å»ºAI Agent"""
        prompt = PromptTemplate.from_template("""
        ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„DevOpsè¿ç»´åŠ©æ‰‹ï¼Œå¸®åŠ©è¯Šæ–­ç³»ç»Ÿé—®é¢˜ã€‚

        å¯ç”¨å·¥å…·ï¼š{tools}

        åˆ†ææ­¥éª¤ï¼š
        1. æ£€æŸ¥æœåŠ¡æ—¥å¿—
        2. æŸ¥çœ‹å…³é”®æŒ‡æ ‡
        3. æ£€æŸ¥èµ„æºçŠ¶æ€
        4. åˆ†æäº‹ä»¶æ—¥å¿—

        æœ€ç»ˆæä¾›ï¼š
        - é—®é¢˜è¯Šæ–­
        - æ ¹æœ¬åŸå› 
        - è§£å†³æ–¹æ¡ˆ
        - é¢„é˜²æªæ–½

        Question: {input}
        Thought: {agent_scratchpad}
        """)

        return create_openai_functions_agent(
            llm=self.llm,
            tools=self.tools,
            prompt=prompt
        )

    async def troubleshoot(
        self,
        service_name: str
    ) -> Dict[str, Any]:
        """æ•…éšœè¯Šæ–­"""
        prompt = f"""
        è¯·è¯Šæ–­æœåŠ¡ {service_name} çš„é—®é¢˜ã€‚

        åˆ†ææ­¥éª¤ï¼š
        1. æ£€æŸ¥æ—¥å¿—ä¸­çš„é”™è¯¯
        2. åˆ†æCPUã€å†…å­˜ã€é”™è¯¯ç‡
        3. æ£€æŸ¥PodçŠ¶æ€
        4. åˆ†æç›¸å…³äº‹ä»¶

        æä¾›ï¼š
        - è¯Šæ–­ç»“æœ
        - æ ¹æœ¬åŸå› 
        - è§£å†³æ–¹æ¡ˆ
        - é¢„é˜²æªæ–½
        """

        diagnosis = await self.ask(prompt)

        return {
            "service": service_name,
            "diagnosis": diagnosis,
            "timestamp": datetime.utcnow().isoformat()
        }

    # å·¥å…·å®ç°
    async def _get_metrics(self, args: str) -> str:
        """è·å–PrometheusæŒ‡æ ‡"""
        from app.integrations.prometheus import prometheus_client

        query, time_range = args.split(", ")
        result = await prometheus_client.query(query, time_range)
        return f"æŒ‡æ ‡æŸ¥è¯¢ç»“æœï¼š{result}"

    async def _query_logs(self, args: str) -> str:
        """æŸ¥è¯¢Elasticsearchæ—¥å¿—"""
        from app.integrations.elasticsearch import es_client

        query, time_range = args.split(", ")
        result = await es_client.search(query, time_range)
        return f"æ—¥å¿—æŸ¥è¯¢ç»“æœï¼š{result}"
```

**2. è‡ªåŠ¨è¯Šæ–­æµç¨‹**

```python
# examples/auto_diagnosis.py
async def auto_diagnosis_flow(service_name: str):
    """è‡ªåŠ¨è¯Šæ–­æµç¨‹"""

    # 1. æ£€æµ‹å¼‚å¸¸
    from app.services.anomaly_service import anomaly_service

    current_metrics = await get_current_metrics(service_name)
    anomaly_result = anomaly_service.detect_anomaly(
        service_name,
        current_metrics
    )

    if anomaly_result['status'] == 'normal':
        print("âœ… æœåŠ¡æ­£å¸¸")
        return

    print(f"âš ï¸ æ£€æµ‹åˆ°å¼‚å¸¸ï¼š{anomaly_result}")

    # 2. AIè¯Šæ–­
    from app.services.ai_service import ai_service

    print("\nğŸ” å¼€å§‹AIè¯Šæ–­...")
    diagnosis = await ai_service.troubleshoot(service_name)

    print(f"""
    è¯Šæ–­æŠ¥å‘Šï¼š
    {diagnosis['diagnosis']}
    """)

    # 3. æå–å…³é”®ä¿¡æ¯
    root_cause = extract_root_cause(diagnosis['diagnosis'])
    solutions = extract_solutions(diagnosis['diagnosis'])

    print(f"""
    æ ¹æœ¬åŸå› ï¼š{root_cause}

    å»ºè®®è§£å†³æ–¹æ¡ˆï¼š
    {chr(10).join(f'  â€¢ {s}' for s in solutions)}
    """)

    # 4. å°è¯•è‡ªåŠ¨ä¿®å¤
    if can_auto_heal(root_cause):
        print("\nğŸ’Š å°è¯•è‡ªåŠ¨ä¿®å¤...")
        result = await auto_heal(service_name, root_cause)
        print(f"ä¿®å¤ç»“æœï¼š{result}")

        # 5. éªŒè¯
        await asyncio.sleep(30)
        new_metrics = await get_current_metrics(service_name)
        new_check = anomaly_service.detect_anomaly(
            service_name,
            new_metrics
        )

        if new_check['status'] == 'normal':
            print("âœ… è‡ªåŠ¨ä¿®å¤æˆåŠŸï¼")
        else:
            print("âŒ è‡ªåŠ¨ä¿®å¤å¤±è´¥ï¼Œéœ€è¦äººå·¥ä»‹å…¥")
```

**3. æ ¹å› åˆ†æï¼ˆRCAï¼‰å¯è§†åŒ–**

```python
# backend/app/services/rca_service.py
class RCAService:
    async def build_rca_tree(
        self,
        service_name: str,
        incident_start: datetime
    ) -> Dict[str, Any]:
        """æ„å»ºæ ¹å› åˆ†ææ ‘"""

        # æ”¶é›†æ‰€æœ‰ç›¸å…³äº‹ä»¶
        events = await self._collect_events(service_name, incident_start)

        # æ„å»ºå› æœå…³ç³»å›¾
        rca_tree = {
            "incident": {
                "service": service_name,
                "time": incident_start,
                "symptoms": await self._identify_symptoms(events),
                "root_causes": await self._identify_root_causes(events),
                "contributing_factors": await self._identify_factors(events),
                "timeline": await self._build_timeline(events)
            }
        }

        return rca_tree

    async def _identify_symptoms(self, events: List[Event]) -> List[str]:
        """è¯†åˆ«ç—‡çŠ¶"""
        symptoms = []
        for event in events:
            if event.type == "alert":
                symptoms.append(f"å‘Šè­¦ï¼š{event.message}")
            elif event.type == "error":
                symptoms.append(f"é”™è¯¯ï¼š{event.message}")
        return symptoms

    async def _identify_root_causes(self, events: List[Event]) -> List[str]:
        """è¯†åˆ«æ ¹æœ¬åŸå› ï¼ˆä½¿ç”¨AIï¼‰"""
        prompt = f"""
        åˆ†æä»¥ä¸‹äº‹ä»¶ï¼Œæ‰¾å‡ºæ ¹æœ¬åŸå› ï¼š

        {format_events(events)}

        æ ¹æœ¬åŸå› é€šå¸¸æ˜¯ï¼š
        - é…ç½®é”™è¯¯
        - èµ„æºä¸è¶³
        - ä¾èµ–æ•…éšœ
        - ä»£ç ç¼ºé™·
        - å¤–éƒ¨å› ç´ 
        """

        from app.services.ai_service import ai_service
        result = await ai_service.ask(prompt)
        return parse_root_causes(result)
```

**å…³é”®ç‚¹**ï¼š
- **å·¥å…·è°ƒç”¨**ï¼šLLMèƒ½å¤Ÿè°ƒç”¨ç›‘æ§å’Œæ—¥å¿—ç³»ç»Ÿ
- **é“¾å¼æ¨ç†**ï¼šé€æ­¥åˆ†æï¼Œé€æ­¥è¯Šæ–­
- **ä¸Šä¸‹æ–‡æ„ŸçŸ¥**ï¼šç»“åˆå†å²æ•°æ®å’Œé…ç½®
- **å¯è§£é‡Šæ€§**ï¼šæ¸…æ™°è¯´æ˜æ¨ç†è¿‡ç¨‹
- **æŒç»­å­¦ä¹ **ï¼šä»å†å²æ•…éšœä¸­å­¦ä¹ 

---

### Q9: å¦‚ä½•å®ç°è‡ªåŠ¨è‡ªæ„ˆç³»ç»Ÿï¼Ÿ

**å‚è€ƒç­”æ¡ˆ**ï¼š

è‡ªåŠ¨è‡ªæ„ˆéœ€è¦ç­–ç•¥å¼•æ“ + æ‰§è¡Œå™¨ + éªŒè¯æœºåˆ¶ã€‚

**1. è‡ªæ„ˆç­–ç•¥å¼•æ“**

```python
# backend/app/services/healing_service.py
class AutoHealingService:
    def __init__(self):
        self.strategies = {
            "high_cpu": self._heal_high_cpu,
            "high_memory": self._heal_high_memory,
            "pod_crash_loop": self._heal_crash_loop,
            "high_error_rate": self._heal_high_error_rate,
        }

    async def analyze_and_heal(
        self,
        service: str,
        issue: Dict[str, Any]
    ) -> Dict[str, Any]:
        """åˆ†æå¹¶å°è¯•è‡ªåŠ¨ä¿®å¤"""

        issue_type = issue.get('type')
        severity = issue.get('severity', 'medium')

        # æ£€æŸ¥æ˜¯å¦æœ‰è‡ªæ„ˆç­–ç•¥
        if issue_type not in self.strategies:
            return {
                "action": "manual_intervention",
                "reason": "No auto-healing strategy"
            }

        # æ ¹æ®ä¸¥é‡åº¦å†³å®š
        if severity in ['low', 'medium']:
            # è‡ªåŠ¨ä¿®å¤
            strategy = self.strategies[issue_type]
            result = await strategy(service, issue)
            return result
        else:
            # é«˜ä¸¥é‡åº¦éœ€è¦äººå·¥ç¡®è®¤
            return {
                "action": "awaiting_approval",
                "reason": "High severity requires approval",
                "suggested_action": self.strategies[issue_type].__name__
            }

    async def _heal_high_cpu(
        self,
        service: str,
        issue: Dict
    ) -> Dict[str, Any]:
        """ä¿®å¤é«˜CPUä½¿ç”¨ç‡"""
        from app.integrations.kubernetes import k8s_client

        try:
            # è·å–å½“å‰å‰¯æœ¬æ•°
            current = k8s_client.get_replicas(service)

            # æ‰©å®¹
            new_replicas = min(current + 2, 10)
            k8s_client.scale_deployment(service, service, new_replicas)

            return {
                "action": "scaled",
                "details": f"Scaled from {current} to {new_replicas}",
                "status": "success"
            }
        except Exception as e:
            return {
                "action": "failed",
                "error": str(e),
                "status": "failed"
            }

    async def _heal_high_memory(
        self,
        service: str,
        issue: Dict
    ) -> Dict[str, Any]:
        """ä¿®å¤é«˜å†…å­˜ä½¿ç”¨ç‡"""
        from app.integrations.kubernetes import k8s_client

        try:
            # é‡å¯ä¸€ä¸ªPodé‡Šæ”¾å†…å­˜
            pods = k8s_client.list_pods(service)
            for pod in pods[:1]:
                k8s_client.delete_pod(service, pod)

            return {
                "action": "restarted_pod",
                "details": f"Restarted pod {pods[0]}",
                "status": "success"
            }
        except Exception as e:
            return {"action": "failed", "error": str(e)}

    async def _heal_crash_loop(
        self,
        service: str,
        issue: Dict
    ) -> Dict[str, Any]:
        """ä¿®å¤Podå´©æºƒå¾ªç¯"""
        # å´©æºƒå¾ªç¯é€šå¸¸éœ€è¦äººå·¥ä»‹å…¥
        return {
            "action": "manual_intervention",
            "reason": "CrashLoopBackOff requires investigation",
            "suggestions": [
                "Check application logs",
                "Verify configuration",
                "Check dependencies",
                "Consider rolling back"
            ]
        }

    async def _heal_high_error_rate(
        self,
        service: str,
        issue: Dict
    ) -> Dict[str, Any]:
        """ä¿®å¤é«˜é”™è¯¯ç‡ï¼ˆä½¿ç”¨AIè¯Šæ–­ï¼‰"""
        from app.services.ai_service import ai_service

        try:
            diagnosis = await ai_service.troubleshoot(service)

            return {
                "action": "ai_diagnosis",
                "diagnosis": diagnosis,
                "status": "analyzed"
            }
        except Exception as e:
            return {"action": "failed", "error": str(e)}
```

**2. è‡ªæ„ˆå·¥ä½œæµ**

```yaml
# infrastructure/argocd/workflows/auto-healing-workflow.yaml
apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  name: auto-healing-workflow
  namespace: argo
spec:
  entrypoint: auto-heal

  templates:
    - name: auto-heal
      steps:
        - - name: detect-issue
            template: detect-issue

        - - name: analyze-severity
            template: analyze-severity

        - - name: decide-action
            template: decide-action

        - - name: execute-healing
            template: execute-healing
            when: "{{steps.decide-action.outputs.result}} == auto-heal"

        - - name: verify-fix
            template: verify-fix

        - - name: manual-intervention
            template: create-ticket
            when: "{{steps.decide-action.outputs.result}} == manual"

    - name: detect-issue
      script:
        image: python:3.11
        command: [python]
        source: |
          import requests
          response = requests.get("http://aiops/api/v1/anomalies/{{inputs.parameters.service}}")
          print(response.json()['status'])

    - name: analyze-severity
      script:
        image: python:3.11
        source: |
          # ä½¿ç”¨AIåˆ†æä¸¥é‡åº¦
          import openai
          severity = openai.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": "è¯„ä¼°é—®é¢˜ä¸¥é‡åº¦..."}]
          )
          print(severity)

    - name: decide-action
      script:
        image: python:3.11
        source: |
          severity = "{{steps.analyze-severity.outputs.result}}"
          if severity in ["low", "medium"]:
            print("auto-heal")
          else:
            print("manual")

    - name: execute-healing
      script:
        image: bitnami/kubectl:latest
        command: [sh, -c]
        source: |
          kubectl scale deployment {{inputs.parameters.service}} \
            --replicas={{inputs.parameters.new-replicas}}

    - name: verify-fix
      script:
        image: python:3.11
        source: |
          import time
          time.sleep(30)
          # éªŒè¯ä¿®å¤æ˜¯å¦æˆåŠŸ

    - name: create-ticket
      script:
        image: python:3.11
        source: |
          # åˆ›å»ºäººå·¥å·¥å•
          import requests
          requests.post("https://jira.example.com/api/issue", ...)
```

**3. è‡ªæ„ˆå®‰å…¨æœºåˆ¶**

```python
# backend/app/services/healing_safety.py
class HealingSafetyService:
    def __init__(self):
        self.max_healings_per_hour = 3
        self.healing_history = {}

    async def can_heal(
        self,
        service: str,
        issue_type: str
    ) -> tuple[bool, str]:
        """æ£€æŸ¥æ˜¯å¦å¯ä»¥æ‰§è¡Œè‡ªæ„ˆ"""

        # 1. æ£€æŸ¥é¢‘ç‡é™åˆ¶
        recent_healings = self._get_recent_healings(service, hours=1)
        if len(recent_healings) >= self.max_healings_per_hour:
            return False, "Too many healing attempts"

        # 2. æ£€æŸ¥ç›¸åŒé—®é¢˜æ˜¯å¦å·²ä¿®å¤è¿‡
        if await self._was_recently_fixed(service, issue_type):
            return False, "Same issue was recently fixed"

        # 3. æ£€æŸ¥æœåŠ¡æ˜¯å¦å¤„äºå…³é”®æ—¶é—´çª—å£
        if await self._is_critical_window(service):
            return False, "Critical time window"

        # 4. æ£€æŸ¥æ˜¯å¦æœ‰å½±å“å…¶ä»–æœåŠ¡çš„é£é™©
        if await self._could_impact_others(service):
            return False, "Could impact dependent services"

        return True, "OK"

    async def record_healing(
        self,
        service: str,
        issue_type: str,
        action: str,
        result: str
    ):
        """è®°å½•è‡ªæ„ˆæ“ä½œ"""
        record = {
            "service": service,
            "issue_type": issue_type,
            "action": action,
            "result": result,
            "timestamp": datetime.utcnow()
        }

        if service not in self.healing_history:
            self.healing_history[service] = []

        self.healing_history[service].append(record)

        # è®°å½•åˆ°å®¡è®¡æ—¥å¿—
        await self._audit_log(record)
```

**å…³é”®ç‚¹**ï¼š
- **ç­–ç•¥é©±åŠ¨**ï¼šä¸åŒé—®é¢˜ç±»å‹ä¸åŒç­–ç•¥
- **å®‰å…¨æœºåˆ¶**ï¼šé¢‘ç‡é™åˆ¶ã€ä¾èµ–æ£€æŸ¥
- **äººå·¥ç¡®è®¤**ï¼šé«˜é£é™©æ“ä½œéœ€å®¡æ‰¹
- **éªŒè¯é—­ç¯**ï¼šä¿®å¤åè‡ªåŠ¨éªŒè¯
- **å®¡è®¡è¿½è¸ª**ï¼šæ‰€æœ‰æ“ä½œå¯è¿½æº¯

---

### Q10: å¦‚ä½•å®ç°æ™ºèƒ½å‘Šè­¦å’Œé™å™ªï¼Ÿ

**å‚è€ƒç­”æ¡ˆ**ï¼š

ä½¿ç”¨AIè¯„ä¼°å‘Šè­¦é‡è¦æ€§ï¼Œå‡å°‘å‘Šè­¦å™ªéŸ³ã€‚

**1. æ™ºèƒ½å‘Šè­¦æœåŠ¡**

```python
# backend/app/services/alert_service.py
class IntelligentAlertingService:
    def __init__(self):
        self.alert_history = {}
        self.similarity_threshold = 0.8

    async def should_alert(
        self,
        alert: Dict[str, Any]
    ) -> tuple[bool, str]:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥å‘é€å‘Šè­¦"""

        # 1. æ£€æŸ¥é‡å¤å‘Šè­¦
        if self._is_duplicate(alert):
            return False, "Duplicate alert filtered"

        # 2. æ£€æŸ¥æ˜¯å¦ä¸ºå·²çŸ¥é—®é¢˜
        if await self._is_known_issue(alert):
            return False, "Known issue, already tracked"

        # 3. ä½¿ç”¨AIè¯„ä¼°é‡è¦æ€§
        importance = await self._evaluate_importance(alert)

        if importance < 0.5:
            return False, f"Low importance: {importance:.2f}"

        # 4. æ£€æŸ¥æ˜¯å¦å¯ä»¥è‡ªåŠ¨ä¿®å¤
        if await self._can_auto_heal(alert):
            return False, "Issue can be auto-healed"

        return True, "Alert sent"

    def _is_duplicate(self, alert: Dict) -> bool:
        """æ£€æŸ¥é‡å¤å‘Šè­¦"""
        key = f"{alert['service']}_{alert['type']}"

        if key not in self.alert_history:
            return False

        last_alert = self.alert_history[key]
        time_diff = datetime.utcnow() - last_alert['timestamp']

        return time_diff < timedelta(minutes=10)

    async def _is_known_issue(self, alert: Dict) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºå·²çŸ¥é—®é¢˜"""
        # æŸ¥è¯¢æ˜¯å¦æœ‰ç›¸åŒçš„æœªè§£å†³äº‹ä»¶
        pass

    async def _evaluate_importance(self, alert: Dict) -> float:
        """AIè¯„ä¼°å‘Šè­¦é‡è¦æ€§ï¼ˆ0-1ï¼‰"""
        from app.services.ai_service import ai_service

        prompt = f"""
        è¯„ä¼°å‘Šè­¦é‡è¦æ€§ï¼ˆ0-1ï¼‰ï¼š

        å‘Šè­¦ä¿¡æ¯ï¼š
        - æœåŠ¡ï¼š{alert['service']}
        - ç±»å‹ï¼š{alert['type']}
        - ä¸¥é‡åº¦ï¼š{alert.get('severity')}
        - æè¿°ï¼š{alert.get('message', '')}

        è€ƒè™‘å› ç´ ï¼š
        1. å½±å“èŒƒå›´
        2. ä¸šåŠ¡å½±å“
        3. ç´§æ€¥ç¨‹åº¦

        åªè¿”å›0-1æ•°å­—ã€‚
        """

        try:
            response = await ai_service.ask(prompt)
            score = float(response.strip())
            return max(0, min(1, score))
        except:
            return 0.5  # é»˜è®¤ä¸­ç­‰é‡è¦æ€§

    async def _can_auto_heal(self, alert: Dict) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯ä»¥è‡ªåŠ¨ä¿®å¤"""
        from app.services.healing_service import healing_service

        return await healing_service.can_heal(
            alert['service'],
            alert['type']
        )
```

**2. å‘Šè­¦èšåˆå’Œåˆ†ç»„**

```python
# backend/app/services/alert_aggregation.py
class AlertAggregationService:
    async def aggregate_alerts(
        self,
        alerts: List[Dict]
    ) -> List[Dict]:
        """èšåˆç›¸ä¼¼å‘Šè­¦"""

        # æŒ‰æœåŠ¡åˆ†ç»„
        grouped = self._group_by_service(alerts)

        # åœ¨æ¯ç»„å†…èšåˆç›¸ä¼¼å‘Šè­¦
        aggregated = []
        for service, service_alerts in grouped.items():
            clusters = self._cluster_similar_alerts(service_alerts)

            for cluster in clusters:
                if len(cluster) > 1:
                    # åˆ›å»ºèšåˆå‘Šè­¦
                    aggregated.append({
                        "type": "aggregated",
                        "service": service,
                        "count": len(cluster),
                        "alerts": cluster,
                        "summary": self._generate_summary(cluster),
                        "severity": self._calculate_aggregate_severity(cluster)
                    })
                else:
                    aggregated.append(cluster[0])

        return aggregated

    def _cluster_similar_alerts(
        self,
        alerts: List[Dict]
    ) -> List[List[Dict]]:
        """ä½¿ç”¨embeddingèšç±»ç›¸ä¼¼å‘Šè­¦"""
        from sklearn.cluster import DBSCAN
        from sentence_transformers import SentenceTransformer

        # ç”Ÿæˆembeddings
        model = SentenceTransformer('all-MiniLM-L6-v2')
        texts = [f"{a['type']}: {a.get('message', '')}" for a in alerts]
        embeddings = model.encode(texts)

        # èšç±»
        clustering = DBSCAN(eps=0.5, min_samples=1).fit(embeddings)
        labels = clustering.labels_

        # æŒ‰clusteråˆ†ç»„
        clusters = {}
        for alert, label in zip(alerts, labels):
            if label not in clusters:
                clusters[label] = []
            clusters[label].append(alert)

        return list(clusters.values())

    def _generate_summary(self, alerts: List[Dict]) -> str:
        """ç”Ÿæˆèšåˆå‘Šè­¦æ‘˜è¦"""
        # ä½¿ç”¨LLMç”Ÿæˆæ‘˜è¦
        from app.services.ai_service import ai_service

        prompt = f"""
        ç®€æ´æ€»ç»“ä»¥ä¸‹å‘Šè­¦ï¼š

        {format_alerts(alerts)}

        æ‘˜è¦ï¼š
        """

        return await ai_service.ask(prompt)
```

**3. å‘Šè­¦è·¯ç”±å’Œå‡çº§**

```python
# backend/app/services/alert_routing.py
class AlertRoutingService:
    def __init__(self):
        self.routing_rules = {
            "critical": {
                "channels": ["pagerduty", "slack", "email"],
                "escalation": "15m"
            },
            "high": {
                "channels": ["slack", "email"],
                "escalation": "30m"
            },
            "medium": {
                "channels": ["slack"],
                "escalation": None
            },
            "low": {
                "channels": ["email"],
                "escalation": None
            }
        }

    async def route_alert(
        self,
        alert: Dict[str, Any]
    ) -> List[str]:
        """è·¯ç”±å‘Šè­¦åˆ°ç›¸åº”æ¸ é“"""
        severity = alert.get('severity', 'medium')
        rule = self.routing_rules.get(severity, self.routing_rules['medium'])

        sent_channels = []

        # å‘é€åˆ°å„ä¸ªæ¸ é“
        for channel in rule['channels']:
            try:
                await self._send_to_channel(channel, alert)
                sent_channels.append(channel)
            except Exception as e:
                print(f"Failed to send to {channel}: {e}")

        # è®¾ç½®å‡çº§
        if rule['escalation']:
            await self._schedule_escalation(
                alert,
                rule['escalation']
            )

        return sent_channels

    async def _schedule_escalation(
        self,
        alert: Dict,
        delay: str
    ):
        """å®‰æ’å‘Šè­¦å‡çº§"""
        # ä½¿ç”¨åå°ä»»åŠ¡è°ƒåº¦
        pass
```

**å…³é”®ç‚¹**ï¼š
- **æ™ºèƒ½è¿‡æ»¤**ï¼šAIè¯„ä¼°é‡è¦æ€§ï¼Œè¿‡æ»¤ä½ä»·å€¼å‘Šè­¦
- **å»é‡èšåˆ**ï¼šç›¸ä¼¼å‘Šè­¦åˆå¹¶
- **ä¸Šä¸‹æ–‡æ„ŸçŸ¥**ï¼šç»“åˆä¸šåŠ¡æ—¶é—´ã€ä¾èµ–å…³ç³»
- **è‡ªé€‚åº”é˜ˆå€¼**ï¼šæ ¹æ®å†å²æ•°æ®åŠ¨æ€è°ƒæ•´
- **é—­ç¯åé¦ˆ**ï¼šæ ¹æ®åé¦ˆä¼˜åŒ–ç­–ç•¥

---

## æœ¬ç« å°ç»“

### DevOpsé¡¹ç›®æ ¸å¿ƒè¦ç‚¹

| é¡¹ç›® | æ ¸å¿ƒæŠ€æœ¯ | å…³é”®èƒ½åŠ› |
|------|---------|---------|
| **å¤šé›†ç¾¤ç®¡ç†** | K8s API, Go, Helm | ç»Ÿä¸€ç®¡ç†ã€è·¨é›†ç¾¤éƒ¨ç½² |
| **å†…éƒ¨å¼€å‘è€…å¹³å°** | Backstage, React | æœåŠ¡ç›®å½•ã€Golden Path |
| **AIOpsæ™ºèƒ½è¿ç»´** | AI/ML, LangChain | å¼‚å¸¸æ£€æµ‹ã€è‡ªæ„ˆã€é¢„æµ‹ |

### é¢è¯•å‡†å¤‡é‡ç‚¹

**æŠ€æœ¯æ·±åº¦**ï¼š
- Kubernetes APIç¼–ç¨‹
- Prometheus/Grafanaç›‘æ§ä½“ç³»
- GitOpsæœ€ä½³å®è·µ
- Backstageæ’ä»¶å¼€å‘
- æœºå™¨å­¦ä¹ åœ¨è¿ç»´ä¸­çš„åº”ç”¨

**æ¶æ„è®¾è®¡**ï¼š
- å¤šé›†ç¾¤æ¶æ„è®¾è®¡
- æœåŠ¡ç›®å½•è®¾è®¡
- AI Agentè®¾è®¡
- è‡ªæ„ˆç­–ç•¥è®¾è®¡

**å®è·µèƒ½åŠ›**ï¼š
- Goåç«¯å¼€å‘
- Python AIå¼€å‘
- Helm Chartå¼€å‘
- Terraformç¼–å†™

---

**å°å¾å¸¦ä½ é£ç³»åˆ—æ•™ç¨‹**

**æœ€åæ›´æ–°ï¼š2026å¹´2æœˆ**
**ç‰ˆæœ¬ï¼šv1.0**
**ä½œè€…ï¼šå°å¾**
**é‚®ç®±ï¼šesimonx@163.com**
