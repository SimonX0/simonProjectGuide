# å®æˆ˜é¡¹ç›®3ï¼šAIOps - AIé©±åŠ¨çš„æ™ºèƒ½è¿ç»´ç³»ç»Ÿ

> **é¡¹ç›®éš¾åº¦**ï¼šâ­â­â­â­â­
> **é¢„è®¡æ—¶é—´**ï¼š80-100å°æ—¶
> **æŠ€æœ¯æ ˆ**ï¼šPython | OpenAI GPT-4 | Prometheus | Elasticsearch | Kubernetes | LangChain | FastAPI

## é¡¹ç›®æ¦‚è¿°

æ„å»ºä¸€ä¸ªAIé©±åŠ¨çš„æ™ºèƒ½è¿ç»´ç³»ç»Ÿï¼ˆAIOpsï¼‰ï¼Œåˆ©ç”¨æœºå™¨å­¦ä¹ å’Œè‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯ï¼Œå®ç°æ•…éšœé¢„æµ‹ã€è‡ªåŠ¨è¯Šæ–­ã€è‡ªæ„ˆèƒ½åŠ›ï¼Œå¤§å¹…é™ä½è¿ç»´æˆæœ¬ï¼Œæé«˜ç³»ç»Ÿç¨³å®šæ€§ã€‚

### æ ¸å¿ƒåŠŸèƒ½

```
ğŸ”® å¼‚å¸¸é¢„æµ‹ï¼šåŸºäºå†å²æ•°æ®é¢„æµ‹æ½œåœ¨æ•…éšœ
ğŸ¤– è‡ªåŠ¨è¯Šæ–­ï¼šAIåˆ†ææ•…éšœæ ¹å› ï¼ˆRCAï¼‰
ğŸ’Š è‡ªåŠ¨è‡ªæ„ˆï¼šè‡ªåŠ¨æ‰§è¡Œä¿®å¤æ“ä½œ
ğŸ“Š æ™ºèƒ½å‘Šè­¦ï¼šå‡å°‘å‘Šè­¦å™ªéŸ³ï¼Œç²¾å‡†å‘Šè­¦
ğŸ¯ å®¹é‡è§„åˆ’ï¼šAIé¢„æµ‹èµ„æºéœ€æ±‚
ğŸ“ˆ è¶‹åŠ¿åˆ†æï¼šè¯†åˆ«ç³»ç»Ÿè¶‹åŠ¿å’Œå¼‚å¸¸
ğŸ” æ—¥å¿—åˆ†æï¼šæ™ºèƒ½æ—¥å¿—åˆ†æå’Œå¼‚å¸¸æ£€æµ‹
ğŸš¨ äº‹ä»¶å…³è”ï¼šè‡ªåŠ¨å…³è”ç›¸å…³äº‹ä»¶
```

### æŠ€æœ¯æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  AIOps Platform                     â”‚
â”‚              (FastAPI + Python)                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚         AI/ML Engine (LangChain)              â”‚ â”‚
â”‚  â”‚  â”œâ”€â”€ Anomaly Detection (Isolation Forest)    â”‚ â”‚
â”‚  â”‚  â”œâ”€â”€ Predictive Analytics (LSTM)             â”‚ â”‚
â”‚  â”‚  â”œâ”€â”€ NLP Analysis (OpenAI GPT-4)             â”‚ â”‚
â”‚  â”‚  â””â”€â”€ Auto-Healing Agent                      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚            Data Pipeline                      â”‚ â”‚
â”‚  â”‚  â”œâ”€â”€ Metrics (Prometheus)                    â”‚ â”‚
â”‚  â”‚  â”œâ”€â”€ Logs (Elasticsearch)                    â”‚ â”‚
â”‚  â”‚  â”œâ”€â”€ Traces (Jaeger)                         â”‚ â”‚
â”‚  â”‚  â””â”€â”€ Events (Kafka)                          â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚               â”‚               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Kubernetes   â”‚ â”‚Prometheusâ”‚ â”‚ Elasticsearch  â”‚
â”‚  (Workloads)  â”‚ â”‚(Metrics) â”‚ â”‚   (Logs)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## é¡¹ç›®æ¶æ„è®¾è®¡

### 1. é¡¹ç›®ç»“æ„

```bash
aiops-platform/
â”œâ”€â”€ backend/                         # Pythonåç«¯
â”‚   â”œâ”€â”€ app/                         # FastAPIåº”ç”¨
â”‚   â”‚   â”œâ”€â”€ api/                     # APIå±‚
â”‚   â”‚   â”‚   â”œâ”€â”€ alerts.py           # å‘Šè­¦æ¥å£
â”‚   â”‚   â”‚   â”œâ”€â”€ incidents.py        # äº‹ä»¶æ¥å£
â”‚   â”‚   â”‚   â”œâ”€â”€ predictions.py      # é¢„æµ‹æ¥å£
â”‚   â”‚   â”‚   â””â”€â”€ diagnosis.py        # è¯Šæ–­æ¥å£
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ core/                    # æ ¸å¿ƒé…ç½®
â”‚   â”‚   â”‚   â”œâ”€â”€ config.py           # é…ç½®ç®¡ç†
â”‚   â”‚   â”‚   â””â”€â”€ security.py         # å®‰å…¨é…ç½®
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ models/                  # æ•°æ®æ¨¡å‹
â”‚   â”‚   â”‚   â”œâ”€â”€ alert.py
â”‚   â”‚   â”‚   â”œâ”€â”€ incident.py
â”‚   â”‚   â”‚   â””â”€â”€ prediction.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ services/                # ä¸šåŠ¡é€»è¾‘
â”‚   â”‚   â”‚   â”œâ”€â”€ ai_service.py       # AIæœåŠ¡
â”‚   â”‚   â”‚   â”œâ”€â”€ alert_service.py    # å‘Šè­¦æœåŠ¡
â”‚   â”‚   â”‚   â”œâ”€â”€ anomaly_service.py  # å¼‚å¸¸æ£€æµ‹
â”‚   â”‚   â”‚   â”œâ”€â”€ prediction_service.py # é¢„æµ‹æœåŠ¡
â”‚   â”‚   â”‚   â””â”€â”€ healing_service.py  # è‡ªæ„ˆæœåŠ¡
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ ml/                      # æœºå™¨å­¦ä¹ 
â”‚   â”‚       â”œâ”€â”€ anomaly_detection.py # å¼‚å¸¸æ£€æµ‹
â”‚   â”‚       â”œâ”€â”€ prediction.py        # æ—¶é—´åºåˆ—é¢„æµ‹
â”‚   â”‚       â”œâ”€â”€ classification.py    # åˆ†ç±»æ¨¡å‹
â”‚   â”‚       â””â”€â”€ training.py          # æ¨¡å‹è®­ç»ƒ
â”‚   â”‚
â”‚   â”œâ”€â”€ agents/                      # AI Agents
â”‚   â”‚   â”œâ”€â”€ troubleshooter.py       # æ•…éšœæ’æŸ¥Agent
â”‚   â”‚   â”œâ”€â”€ optimizer.py            # ä¼˜åŒ–Agent
â”‚   â”‚   â””â”€â”€ reporter.py             # æŠ¥å‘Šç”ŸæˆAgent
â”‚   â”‚
â”‚   â”œâ”€â”€ integrations/                # é›†æˆ
â”‚   â”‚   â”œâ”€â”€ prometheus.py           # Prometheusé›†æˆ
â”‚   â”‚   â”œâ”€â”€ elasticsearch.py        # ESé›†æˆ
â”‚   â”‚   â”œâ”€â”€ kubernetes.py           # K8sé›†æˆ
â”‚   â”‚   â””â”€â”€ opsgenie.py             # Opsgenieé›†æˆ
â”‚   â”‚
â”‚   â”œâ”€â”€ tests/                       # æµ‹è¯•
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ frontend/                        # Vue3å‰ç«¯
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ views/
â”‚   â”‚   â”‚   â”œâ”€â”€ Dashboard.vue       # ä»ªè¡¨ç›˜
â”‚   â”‚   â”‚   â”œâ”€â”€ Alerts.vue          # å‘Šè­¦åˆ—è¡¨
â”‚   â”‚   â”‚   â”œâ”€â”€ Incidents.vue       # äº‹ä»¶ç®¡ç†
â”‚   â”‚   â”‚   â”œâ”€â”€ Predictions.vue     # é¢„æµ‹åˆ†æ
â”‚   â”‚   â”‚   â””â”€â”€ Diagnosis.vue       # AIè¯Šæ–­
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â””â”€â”€ api/
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ infrastructure/                  # åŸºç¡€è®¾æ–½
â”‚   â”œâ”€â”€ terraform/                  # IaC
â”‚   â”œâ”€â”€ kubernetes/                 # K8sé…ç½®
â”‚   â””â”€â”€ docker/
â”‚
â”œâ”€â”€ ml/                             # MLæ¨¡å‹
â”‚   â”œâ”€â”€ models/                     # è®­ç»ƒå¥½çš„æ¨¡å‹
â”‚   â”œâ”€â”€ data/                       # è®­ç»ƒæ•°æ®
â”‚   â””â”€â”€ notebooks/                  # Jupyter notebooks
â”‚
â”œâ”€â”€ scripts/                        # è„šæœ¬
â”‚   â”œâ”€â”€ train_models.py            # æ¨¡å‹è®­ç»ƒ
â”‚   â””â”€â”€ evaluate.py                # æ¨¡å‹è¯„ä¼°
â”‚
â””â”€â”€ docs/                           # æ–‡æ¡£
    â”œâ”€â”€ architecture.md
    â”œâ”€â”€ api.md
    â””â”€â”€ user_guide.md
```

### 2. æŠ€æœ¯é€‰å‹

| ç»„ä»¶ | æŠ€æœ¯é€‰å‹ | è¯´æ˜ |
|------|---------|------|
| **åç«¯æ¡†æ¶** | FastAPI | é«˜æ€§èƒ½Pythonæ¡†æ¶ |
| **AIå¼•æ“** | LangChain + GPT-4 | LLMæ¡†æ¶ |
| **æœºå™¨å­¦ä¹ ** | scikit-learn, PyTorch | ML/DLæ¡†æ¶ |
| **å¼‚å¸¸æ£€æµ‹** | Isolation Forest | æ— ç›‘ç£å­¦ä¹  |
| **æ—¶é—´åºåˆ—** | Prophet, LSTM | é¢„æµ‹æ¨¡å‹ |
| **ç›‘æ§** | Prometheus | æŒ‡æ ‡é‡‡é›† |
| **æ—¥å¿—** | Elasticsearch | æ—¥å¿—å­˜å‚¨ |
| **å®¹å™¨** | Kubernetes | å®¹å™¨ç¼–æ’ |
| **æ¶ˆæ¯é˜Ÿåˆ—** | Kafka | äº‹ä»¶æµ |
| **æ•°æ®åº“** | PostgreSQL + TimescaleDB | æ—¶åºæ•°æ®åº“ |

---

## æ ¸å¿ƒåŠŸèƒ½å®ç°

### 1. AIæœåŠ¡æ ¸å¿ƒ

```python
# backend/app/services/ai_service.py
from langchain.agents import AgentExecutor, create_openai_functions_agent
from langchain.tools import Tool
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from typing import List, Dict, Any
import asyncio

class AIService:
    """AIæœåŠ¡ï¼šæ ¸å¿ƒAIèƒ½åŠ›"""

    def __init__(self):
        self.llm = ChatOpenAI(
            model="gpt-4-turbo-preview",
            temperature=0
        )
        self.tools = self._create_tools()
        self.agent = self._create_agent()

    def _create_tools(self) -> List[Tool]:
        """åˆ›å»ºAIå·¥å…·é›†"""
        return [
            Tool(
                name="GetMetrics",
                func=self._get_metrics,
                description="è·å–PrometheusæŒ‡æ ‡æ•°æ®ï¼Œæ ¼å¼ï¼šquery, time_range"
            ),
            Tool(
                name="QueryLogs",
                func=self._query_logs,
                description="æŸ¥è¯¢Elasticsearchæ—¥å¿—ï¼Œæ ¼å¼ï¼šquery, time_range"
            ),
            Tool(
                name="GetPodStatus",
                func=self._get_pod_status,
                description="è·å–Kubernetes PodçŠ¶æ€ï¼Œæ ¼å¼ï¼šnamespace, pod_name"
            ),
            Tool(
                name="ScaleDeployment",
                func=self._scale_deployment,
                description="æ‰©å®¹Deploymentï¼Œæ ¼å¼ï¼šnamespace, deployment, replicas"
            ),
            Tool(
                name="RestartPod",
                func=self._restart_pod,
                description="é‡å¯Podï¼Œæ ¼å¼ï¼šnamespace, pod_name"
            ),
            Tool(
                name="AnalyzeAnomaly",
                func=self._analyze_anomaly,
                description="åˆ†æå¼‚å¸¸æŒ‡æ ‡ï¼Œæ ¼å¼ï¼šservice_name"
            ),
            Tool(
                name="GetEvents",
                func=self._get_events,
                description="è·å–Kubernetesäº‹ä»¶ï¼Œæ ¼å¼ï¼šnamespace"
            ),
        ]

    def _create_agent(self):
        """åˆ›å»ºAI Agent"""
        prompt = PromptTemplate.from_template("""
        ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„DevOpsè¿ç»´åŠ©æ‰‹ï¼Œå¸®åŠ©å¼€å‘è€…è¯Šæ–­å’Œè§£å†³ç³»ç»Ÿé—®é¢˜ã€‚

        ä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å·¥å…·ï¼š
        {tools}

        å·¥å…·ä½¿ç”¨æ ¼å¼ï¼š
        Question: è¾“å…¥é—®é¢˜
        Thought: æ€è€ƒåº”è¯¥ä½¿ç”¨ä»€ä¹ˆå·¥å…·
        Action: å·¥å…·åç§°
        Action Input: å·¥å…·è¾“å…¥å‚æ•°
        Observation: å·¥å…·æ‰§è¡Œç»“æœ
        ... (å¯ä»¥é‡å¤Thought/Action/Observation)
        Thought: æˆ‘ç°åœ¨çŸ¥é“æœ€ç»ˆç­”æ¡ˆäº†
        Final Answer: æ€»ç»“ä½ çš„åˆ†æå’Œå»ºè®®

        å¼€å§‹ï¼

        Question: {input}
        Thought: {agent_scratchpad}
        """)

        return create_openai_functions_agent(
            llm=self.llm,
            tools=self.tools,
            prompt=prompt
        )

    async def ask(self, question: str) -> str:
        """è¯¢é—®AIåŠ©æ‰‹"""
        agent_executor = AgentExecutor(
            agent=self.agent,
            tools=self.tools,
            verbose=True,
            max_iterations=10
        )

        try:
            result = await agent_executor.ainvoke({"input": question})
            return result["output"]
        except Exception as e:
            return f"æŠ±æ­‰ï¼Œæˆ‘é‡åˆ°äº†ä¸€äº›é—®é¢˜ï¼š{str(e)}"

    async def troubleshoot(self, service_name: str) -> Dict[str, Any]:
        """æ•…éšœæ’æŸ¥"""
        prompt = f"""
        è¯·å¸®æˆ‘æ’æŸ¥æœåŠ¡ {service_name} çš„å½“å‰é—®é¢˜ã€‚

        è¯·æŒ‰ä»¥ä¸‹æ­¥éª¤è¿›è¡Œåˆ†æï¼š
        1. æ£€æŸ¥æœåŠ¡æ—¥å¿—ä¸­çš„é”™è¯¯ä¿¡æ¯
        2. æŸ¥çœ‹å…³é”®æŒ‡æ ‡ï¼ˆCPUã€å†…å­˜ã€é”™è¯¯ç‡ï¼‰
        3. æ£€æŸ¥Kubernetesèµ„æºçŠ¶æ€
        4. åˆ†æç›¸å…³äº‹ä»¶

        ç„¶åæä¾›ï¼š
        - é—®é¢˜è¯Šæ–­
        - å¯èƒ½çš„æ ¹æœ¬åŸå› 
        - å»ºè®®çš„è§£å†³æ–¹æ¡ˆ
        - é¢„é˜²æªæ–½
        """

        diagnosis = await self.ask(prompt)

        return {
            "service": service_name,
            "diagnosis": diagnosis,
            "timestamp": datetime.utcnow().isoformat()
        }

    # å·¥å…·å®ç°
    async def _get_metrics(self, args: str) -> str:
        """è·å–æŒ‡æ ‡"""
        from app.integrations.prometheus import prometheus_client

        try:
            query, time_range = args.split(", ")
            result = prometheus_client.query(query, time_range)
            return f"æŒ‡æ ‡æŸ¥è¯¢ç»“æœï¼š{result}"
        except Exception as e:
            return f"è·å–æŒ‡æ ‡å¤±è´¥ï¼š{str(e)}"

    async def _query_logs(self, args: str) -> str:
        """æŸ¥è¯¢æ—¥å¿—"""
        from app.integrations.elasticsearch import es_client

        try:
            query, time_range = args.split(", ")
            result = es_client.search(query, time_range)
            return f"æ—¥å¿—æŸ¥è¯¢ç»“æœï¼š{result}"
        except Exception as e:
            return f"æŸ¥è¯¢æ—¥å¿—å¤±è´¥ï¼š{str(e)}"

    async def _get_pod_status(self, args: str) -> str:
        """è·å–PodçŠ¶æ€"""
        from app.integrations.kubernetes import k8s_client

        try:
            namespace, pod_name = args.split(", ")
            status = k8s_client.get_pod_status(namespace, pod_name)
            return f"PodçŠ¶æ€ï¼š{status}"
        except Exception as e:
            return f"è·å–PodçŠ¶æ€å¤±è´¥ï¼š{str(e)}"

    async def _scale_deployment(self, args: str) -> str:
        """æ‰©å®¹Deployment"""
        from app.integrations.kubernetes import k8s_client

        try:
            namespace, deployment, replicas = args.split(", ")
            k8s_client.scale_deployment(namespace, deployment, int(replicas))
            return f"å·²æ‰©å®¹ {deployment} åˆ° {replicas} ä¸ªå‰¯æœ¬"
        except Exception as e:
            return f"æ‰©å®¹å¤±è´¥ï¼š{str(e)}"

    async def _restart_pod(self, args: str) -> str:
        """é‡å¯Pod"""
        from app.integrations.kubernetes import k8s_client

        try:
            namespace, pod_name = args.split(", ")
            k8s_client.delete_pod(namespace, pod_name)
            return f"å·²é‡å¯Pod {pod_name}"
        except Exception as e:
            return f"é‡å¯Podå¤±è´¥ï¼š{str(e)}"

    async def _analyze_anomaly(self, args: str) -> str:
        """åˆ†æå¼‚å¸¸"""
        from app.services.anomaly_service import anomaly_service

        try:
            result = await anomaly_service.detect_anomaly(args)
            return f"å¼‚å¸¸åˆ†æç»“æœï¼š{result}"
        except Exception as e:
            return f"å¼‚å¸¸åˆ†æå¤±è´¥ï¼š{str(e)}"

    async def _get_events(self, args: str) -> str:
        """è·å–Kubernetesäº‹ä»¶"""
        from app.integrations.kubernetes import k8s_client

        try:
            events = k8s_client.get_events(args)
            return f"Kubernetesäº‹ä»¶ï¼š{events}"
        except Exception as e:
            return f"è·å–äº‹ä»¶å¤±è´¥ï¼š{str(e)}"
```

### 2. å¼‚å¸¸æ£€æµ‹æœåŠ¡

```python
# backend/app/services/anomaly_service.py
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import StandardScaler
import numpy as np
from typing import List, Dict, Any, Optional
from datetime import datetime, timedelta

class AnomalyDetectionService:
    """å¼‚å¸¸æ£€æµ‹æœåŠ¡"""

    def __init__(self):
        self.scaler = StandardScaler()
        self.models = {}  # æ¯ä¸ªæœåŠ¡ä¸€ä¸ªæ¨¡å‹
        self.threshold = -0.5  # å¼‚å¸¸é˜ˆå€¼

    def train_model(self, service_name: str, metrics: np.ndarray):
        """è®­ç»ƒå¼‚å¸¸æ£€æµ‹æ¨¡å‹"""
        # æ ‡å‡†åŒ–æ•°æ®
        scaled_metrics = self.scaler.fit_transform(metrics)

        # è®­ç»ƒIsolation Forest
        model = IsolationForest(
            contamination=0.1,  # å¼‚å¸¸æ¯”ä¾‹
            random_state=42
        )
        model.fit(scaled_metrics)

        # ä¿å­˜æ¨¡å‹
        self.models[service_name] = model

    def detect_anomaly(self, service_name: str, current_metrics: Dict[str, float]) -> Dict[str, Any]:
        """å®æ—¶å¼‚å¸¸æ£€æµ‹"""
        if service_name not in self.models:
            return {
                "service": service_name,
                "status": "no_model",
                "message": "No trained model for this service"
            }

        model = self.models[service_name]

        # æå–ç‰¹å¾
        features = np.array([[
            current_metrics.get('cpu_usage', 0),
            current_metrics.get('memory_usage', 0),
            current_metrics.get('error_rate', 0),
            current_metrics.get('latency_p95', 0),
            current_metrics.get('request_rate', 0),
        ]])

        # æ ‡å‡†åŒ–
        scaled_features = self.scaler.transform(features)

        # é¢„æµ‹
        prediction = model.predict(scaled_features)[0]
        score = model.score_samples(scaled_features)[0]

        is_anomaly = prediction == -1 or score < self.threshold

        return {
            "service": service_name,
            "status": "anomaly" if is_anomaly else "normal",
            "anomaly_score": float(score),
            "metrics": current_metrics,
            "timestamp": datetime.utcnow().isoformat(),
            "severity": self._calculate_severity(score)
        }

    def _calculate_severity(self, score: float) -> str:
        """è®¡ç®—å¼‚å¸¸ä¸¥é‡ç¨‹åº¦"""
        if score < -0.8:
            return "critical"
        elif score < -0.6:
            return "high"
        elif score < -0.4:
            return "medium"
        else:
            return "low"

    async def batch_detect(self, services: List[str]) -> List[Dict[str, Any]]:
        """æ‰¹é‡æ£€æµ‹å¤šä¸ªæœåŠ¡"""
        from app.integrations.prometheus import prometheus_client

        results = []

        for service in services:
            # è·å–å½“å‰æŒ‡æ ‡
            metrics = await prometheus_client.get_current_metrics(service)

            # æ£€æµ‹å¼‚å¸¸
            result = self.detect_anomaly(service, metrics)
            results.append(result)

        return results
```

### 3. é¢„æµ‹æœåŠ¡

```python
# backend/app/services/prediction_service.py
from prophet import Prophet
import pandas as pd
from typing import Dict, Any, List
from datetime import datetime, timedelta

class PredictionService:
    """é¢„æµ‹æœåŠ¡"""

    def __init__(self):
        self.models = {}

    def train_prediction_model(self, service_name: str, historical_data: pd.DataFrame):
        """è®­ç»ƒé¢„æµ‹æ¨¡å‹"""
        # Prophetè¦æ±‚æ•°æ®æ ¼å¼ï¼šds (datetime), y (value)
        df = historical_data.rename(columns={'timestamp': 'ds', 'value': 'y'})

        # åˆ›å»ºProphetæ¨¡å‹
        model = Prophet(
            yearly_seasonality=True,
            weekly_seasonality=True,
            daily_seasonality=True,
            interval_width=0.95  # é¢„æµ‹åŒºé—´
        )

        # è®­ç»ƒ
        model.fit(df)

        # ä¿å­˜æ¨¡å‹
        self.models[service_name] = model

    async def predict_capacity(self, service_name: str, hours: int = 24) -> Dict[str, Any]:
        """é¢„æµ‹å®¹é‡éœ€æ±‚"""
        if service_name not in self.models:
            return {"error": "No trained model"}

        model = self.models[service_name]

        # åˆ›å»ºæœªæ¥æ—¶é—´ç‚¹
        future = model.make_future_dataframe(periods=hours, freq='H')

        # é¢„æµ‹
        forecast = model.predict(future)

        # æå–é¢„æµ‹ç»“æœ
        predictions = forecast.tail(hours)[['ds', 'yhat', 'yhat_lower', 'yhat_upper']]

        # è®¡ç®—æ¨èé…ç½®
        peak_demand = predictions['yhat'].max()
        avg_demand = predictions['yhat'].mean()

        return {
            "service": service_name,
            "predictions": predictions.to_dict('records'),
            "recommendations": {
                "peak_cpu": float(peak_demand),
                "avg_cpu": float(avg_demand),
                "recommended_replicas": self._calculate_replicas(peak_demand),
                "scale_up_threshold": float(peak_demand * 0.8),
            },
            "forecast_horizon": f"{hours} hours",
            "generated_at": datetime.utcnow().isoformat()
        }

    def _calculate_replicas(self, cpu_demand: float) -> int:
        """æ ¹æ®CPUéœ€æ±‚è®¡ç®—å‰¯æœ¬æ•°"""
        # å‡è®¾æ¯ä¸ªå‰¯æœ¬èƒ½å¤„ç†50% CPU
        single_pod_capacity = 50
        replicas = int(np.ceil(cpu_demand / single_pod_capacity))
        return max(2, min(10, replicas))  # æœ€å°‘2ä¸ªï¼Œæœ€å¤š10ä¸ª

    async def predict_failure(self, service_name: str, hours: int = 24) -> Dict[str, Any]:
        """é¢„æµ‹æ•…éšœæ¦‚ç‡"""
        from app.services.anomaly_service import anomaly_service

        # è·å–å†å²å¼‚å¸¸åˆ†æ•°
        historical_anomalies = await self._get_historical_anomalies(service_name, days=30)

        # è®¡ç®—è¶‹åŠ¿
        if len(historical_anomalies) == 0:
            return {"probability": 0, "confidence": "low"}

        recent_anomalies = historical_anomalies[-7:]  # æœ€è¿‘7å¤©
        anomaly_rate = len([a for a in recent_anomalies if a['is_anomaly']]) / len(recent_anomalies)

        # åŸºäºå¼‚å¸¸ç‡é¢„æµ‹æ•…éšœæ¦‚ç‡
        failure_probability = min(anomaly_rate * 2, 1.0)  # æœ€é«˜100%

        return {
            "service": service_name,
            "failure_probability": failure_probability,
            "confidence": "high" if len(historical_anomalies) >= 30 else "medium",
            "risk_factors": await self._identify_risk_factors(service_name),
            "preventive_actions": await self._suggest_preventive_actions(service_name),
        }

    async def _get_historical_anomalies(self, service_name: str, days: int) -> List[Dict]:
        """è·å–å†å²å¼‚å¸¸æ•°æ®"""
        # ä»æ•°æ®åº“æˆ–æ—¶åºæ•°æ®åº“è·å–
        pass

    async def _identify_risk_factors(self, service_name: str) -> List[str]:
        """è¯†åˆ«é£é™©å› ç´ """
        # ä½¿ç”¨AIåˆ†æé£é™©å› ç´ 
        pass

    async def _suggest_preventive_actions(self, service_name: str) -> List[str]:
        """å»ºè®®é¢„é˜²æªæ–½"""
        # ä½¿ç”¨AIç”Ÿæˆå»ºè®®
        pass
```

### 4. è‡ªæ„ˆæœåŠ¡

```python
# backend/app/services/healing_service.py
from typing import Dict, Any, List
from datetime import datetime
import asyncio

class AutoHealingService:
    """è‡ªåŠ¨è‡ªæ„ˆæœåŠ¡"""

    def __init__(self):
        self.healing_strategies = {
            "high_cpu": self._heal_high_cpu,
            "high_memory": self._heal_high_memory,
            "pod_crash_loop": self._heal_crash_loop,
            "high_error_rate": self._heal_high_error_rate,
        }

    async def analyze_and_heal(self, service: str, issue: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†æå¹¶å°è¯•è‡ªåŠ¨ä¿®å¤é—®é¢˜"""
        # 1. åˆ†æé—®é¢˜ç±»å‹
        issue_type = issue.get('type')
        severity = issue.get('severity', 'medium')

        # 2. æ£€æŸ¥æ˜¯å¦æœ‰è‡ªæ„ˆç­–ç•¥
        if issue_type not in self.healing_strategies:
            return {
                "action": "manual_intervention",
                "reason": "No auto-healing strategy for this issue type"
            }

        # 3. æ‰§è¡Œè‡ªæ„ˆç­–ç•¥
        if severity in ['low', 'medium']:
            # ä½ä¸¥é‡åº¦é—®é¢˜å¯ä»¥è‡ªåŠ¨ä¿®å¤
            strategy = self.healing_strategies[issue_type]
            result = await strategy(service, issue)
            return result
        else:
            # é«˜ä¸¥é‡åº¦é—®é¢˜éœ€è¦äººå·¥ç¡®è®¤
            return {
                "action": "awaiting_approval",
                "reason": "High severity issue requires manual approval",
                "suggested_action": self.healing_strategies[issue_type].__name__
            }

    async def _heal_high_cpu(self, service: str, issue: Dict) -> Dict[str, Any]:
        """ä¿®å¤é«˜CPUä½¿ç”¨ç‡"""
        from app.integrations.kubernetes import k8s_client

        try:
            # è·å–å½“å‰å‰¯æœ¬æ•°
            current_replicas = k8s_client.get_replicas(service)

            # æ‰©å®¹
            new_replicas = min(current_replicas + 2, 10)
            k8s_client.scale_deployment(service, service, new_replicas)

            return {
                "action": "scaled",
                "details": f"Scaled {service} from {current_replicas} to {new_replicas} replicas",
                "status": "success"
            }
        except Exception as e:
            return {
                "action": "failed",
                "error": str(e),
                "status": "failed"
            }

    async def _heal_high_memory(self, service: str, issue: Dict) -> Dict[str, Any]:
        """ä¿®å¤é«˜å†…å­˜ä½¿ç”¨ç‡"""
        # é‡å¯Podä»¥é‡Šæ”¾å†…å­˜
        from app.integrations.kubernetes import k8s_client

        try:
            pods = k8s_client.list_pods(service)
            for pod in pods[:1]:  # é‡å¯ä¸€ä¸ªPod
                k8s_client.delete_pod(service, pod)

            return {
                "action": "restarted_pod",
                "details": f"Restarted pod {pods[0]}",
                "status": "success"
            }
        except Exception as e:
            return {
                "action": "failed",
                "error": str(e),
                "status": "failed"
            }

    async def _heal_crash_loop(self, service: str, issue: Dict) -> Dict[str, Any]:
        """ä¿®å¤Podå´©æºƒå¾ªç¯"""
        # å´©æºƒå¾ªç¯é€šå¸¸éœ€è¦äººå·¥ä»‹å…¥
        return {
            "action": "manual_intervention",
            "reason": "CrashLoopBackOff usually requires investigation",
            "suggestions": [
                "Check application logs",
                "Verify configuration",
                "Check dependencies",
                "Consider rolling back"
            ]
        }

    async def _heal_high_error_rate(self, service: str, issue: Dict) -> Dict[str, Any]:
        """ä¿®å¤é«˜é”™è¯¯ç‡"""
        # ä½¿ç”¨AIåˆ†æé”™è¯¯åŸå› å¹¶å»ºè®®ä¿®å¤æ–¹æ¡ˆ
        from app.services.ai_service import ai_service

        try:
            diagnosis = await ai_service.troubleshoot(service)

            return {
                "action": "ai_diagnosis",
                "diagnosis": diagnosis,
                "status": "analyzed"
            }
        except Exception as e:
            return {
                "action": "failed",
                "error": str(e),
                "status": "failed"
            }
```

### 5. æ™ºèƒ½å‘Šè­¦æœåŠ¡

```python
# backend/app/services/alert_service.py
from typing import Dict, Any, List
from datetime import datetime, timedelta

class IntelligentAlertingService:
    """æ™ºèƒ½å‘Šè­¦æœåŠ¡"""

    def __init__(self):
        self.alert_history = {}  # å‘Šè­¦å†å²
        self.similarity_threshold = 0.8  # ç›¸ä¼¼åº¦é˜ˆå€¼

    async def should_alert(self, alert: Dict[str, Any]) -> tuple[bool, str]:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥å‘é€å‘Šè­¦ï¼ˆå‡å°‘å‘Šè­¦å™ªéŸ³ï¼‰"""

        # 1. æ£€æŸ¥æ˜¯å¦ä¸ºé‡å¤å‘Šè­¦
        if self._is_duplicate(alert):
            return False, "Duplicate alert filtered"

        # 2. æ£€æŸ¥æ˜¯å¦ä¸ºå·²çŸ¥é—®é¢˜
        if self._is_known_issue(alert):
            return False, "Known issue, already tracked"

        # 3. ä½¿ç”¨AIåˆ¤æ–­å‘Šè­¦é‡è¦æ€§
        importance = await self._evaluate_importance(alert)

        if importance < 0.5:
            return False, f"Low importance score: {importance:.2f}"

        # 4. æ£€æŸ¥æ˜¯å¦å¯ä»¥è‡ªåŠ¨ä¿®å¤
        can_auto_heal = await self._can_auto_heal(alert)
        if can_auto_heal:
            return False, "Issue can be auto-healed"

        return True, "Alert sent"

    def _is_duplicate(self, alert: Dict) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºé‡å¤å‘Šè­¦"""
        key = f"{alert['service']}_{alert['type']}"

        if key not in self.alert_history:
            return False

        # æ£€æŸ¥æ—¶é—´çª—å£å†…æ˜¯å¦æœ‰ç›¸åŒå‘Šè­¦
        last_alert = self.alert_history[key]
        time_diff = datetime.utcnow() - last_alert['timestamp']

        return time_diff < timedelta(minutes=10)

    def _is_known_issue(self, alert: Dict) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºå·²çŸ¥é—®é¢˜"""
        # ä»æ•°æ®åº“æŸ¥è¯¢æ˜¯å¦æœ‰ç›¸åŒçš„æœªè§£å†³äº‹ä»¶
        pass

    async def _evaluate_importance(self, alert: Dict) -> float:
        """è¯„ä¼°å‘Šè­¦é‡è¦æ€§ï¼ˆä½¿ç”¨AIï¼‰"""
        from app.services.ai_service import ai_service

        prompt = f"""
        è¯„ä¼°ä»¥ä¸‹å‘Šè­¦çš„é‡è¦æ€§ï¼ˆ0-1ä¹‹é—´çš„åˆ†æ•°ï¼‰ï¼š

        å‘Šè­¦ä¿¡æ¯ï¼š
        - æœåŠ¡ï¼š{alert['service']}
        - ç±»å‹ï¼š{alert['type']}
        - ä¸¥é‡åº¦ï¼š{alert.get('severity', 'unknown')}
        - æè¿°ï¼š{alert.get('message', '')}

        è¯·è€ƒè™‘ï¼š
        1. å½±å“èŒƒå›´
        2. ä¸šåŠ¡å½±å“
        3. ç´§æ€¥ç¨‹åº¦

        åªè¿”å›0-1ä¹‹é—´çš„æ•°å­—ï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚
        """

        try:
            response = await ai_service.ask(prompt)
            score = float(response.strip())
            return max(0, min(1, score))  # ç¡®ä¿åœ¨0-1ä¹‹é—´
        except:
            return 0.5  # é»˜è®¤ä¸­ç­‰é‡è¦æ€§

    async def _can_auto_heal(self, alert: Dict) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯ä»¥è‡ªåŠ¨ä¿®å¤"""
        # æ£€æŸ¥æ˜¯å¦æœ‰å¯¹åº”çš„è‡ªæ„ˆç­–ç•¥
        pass
```

### 6. APIæ¥å£

```python
# backend/app/api/predictions.py
from fastapi import APIRouter, Depends, HTTPException
from typing import List
from app.services.prediction_service import PredictionService
from app.services.ai_service import AIService

router = APIRouter(prefix="/api/v1/predictions", tags=["predictions"])

prediction_service = PredictionService()
ai_service = AIService()

@router.post("/{service_name}/capacity")
async def predict_capacity(service_name: str, hours: int = 24):
    """é¢„æµ‹å®¹é‡éœ€æ±‚"""
    result = await prediction_service.predict_capacity(service_name, hours)
    return result

@router.post("/{service_name}/failure")
async def predict_failure(service_name: str, hours: int = 24):
    """é¢„æµ‹æ•…éšœæ¦‚ç‡"""
    result = await prediction_service.predict_failure(service_name, hours)
    return result

@router.post("/analyze")
async def analyze_system(services: List[str]):
    """åˆ†ææ•´ä¸ªç³»ç»Ÿ"""
    from app.services.anomaly_service import anomaly_service

    anomalies = await anomaly_service.batch_detect(services)
    return {
        "services_analyzed": len(services),
        "anomalies_detected": len([a for a in anomalies if a['status'] == 'anomaly']),
        "details": anomalies
    }
```

---

## å®é™…åº”ç”¨åœºæ™¯

### åœºæ™¯1ï¼šè‡ªåŠ¨æ•…éšœè¯Šæ–­å’Œä¿®å¤

```python
# examples/auto_healing_scenario.py
from app.services.ai_service import AIService
from app.services.healing_service import AutoHealingService
import asyncio

async def auto_healing_scenario():
    """è‡ªåŠ¨æ•…éšœè¯Šæ–­å’Œä¿®å¤åœºæ™¯"""
    ai_service = AIService()
    healing_service = AutoHealingService()

    # 1. ç›‘æ§å‘ç°å¼‚å¸¸
    alert = {
        "service": "user-service",
        "namespace": "production",
        "type": "high_error_rate",
        "value": 0.15,  # 15%é”™è¯¯ç‡
        "threshold": 0.05,
        "severity": "high"
    }

    print(f"âš ï¸  æ£€æµ‹åˆ°å¼‚å¸¸ï¼š{alert}")

    # 2. æ™ºèƒ½å‘Šè­¦åˆ¤æ–­
    from app.services.alert_service import IntelligentAlertingService
    alert_service = IntelligentAlertingService()

    should_send, reason = await alert_service.should_alert(alert)
    print(f"ğŸ“Š å‘Šè­¦å†³ç­–ï¼š{should_send}, åŸå› ï¼š{reason}")

    if not should_send:
        print("å‘Šè­¦è¢«è¿‡æ»¤ï¼Œæ— éœ€äººå·¥ä»‹å…¥")
        return

    # 3. AIè‡ªåŠ¨è¯Šæ–­
    print("\nğŸ” å¼€å§‹AIè¯Šæ–­...")
    diagnosis = await ai_service.troubleshoot(alert["service"])
    print(f"è¯Šæ–­ç»“æœï¼š\n{diagnosis['diagnosis']}")

    # 4. å°è¯•è‡ªåŠ¨ä¿®å¤
    if alert["severity"] == "high":
        print("\nğŸ’Š å°è¯•è‡ªåŠ¨ä¿®å¤...")
        healing_result = await healing_service.analyze_and_heal(
            alert["service"],
            alert
        )
        print(f"ä¿®å¤ç»“æœï¼š{healing_result}")

        # 5. éªŒè¯ä¿®å¤æ•ˆæœ
        if healing_result.get("status") == "success":
            print("\nâœ… ç­‰å¾…30ç§’åéªŒè¯ä¿®å¤æ•ˆæœ...")
            await asyncio.sleep(30)

            # é‡æ–°æ£€æŸ¥
            from app.services.anomaly_service import AnomalyDetectionService
            anomaly_service = AnomalyDetectionService()

            current_metrics = {
                "cpu_usage": 45,
                "memory_usage": 60,
                "error_rate": 0.02,
                "latency_p95": 150,
                "request_rate": 500
            }

            check = anomaly_service.detect_anomaly(
                alert["service"],
                current_metrics
            )

            if check["status"] == "normal":
                print("âœ… è‡ªåŠ¨ä¿®å¤æˆåŠŸï¼")
            else:
                print("âŒ è‡ªåŠ¨ä¿®å¤å¤±è´¥ï¼Œéœ€è¦äººå·¥ä»‹å…¥")
                # åˆ›å»ºäººå·¥å·¥å•
                print("ğŸ« åˆ›å»ºäººå·¥å·¥å•...")
        else:
            print("âŒ æ— æ³•è‡ªåŠ¨ä¿®å¤ï¼Œéœ€è¦äººå·¥ä»‹å…¥")
    else:
        print("â„¹ï¸  é—®é¢˜ä¸ä¸¥é‡ï¼ŒæŒç»­ç›‘æ§ä¸­")

# è¿è¡Œåœºæ™¯
asyncio.run(auto_healing_scenario())
```

### åœºæ™¯2ï¼šé¢„æµ‹æ€§ç»´æŠ¤

```python
# examples/predictive_maintenance.py
from app.services.prediction_service import PredictionService
import asyncio

async def predictive_maintenance_scenario():
    """é¢„æµ‹æ€§ç»´æŠ¤åœºæ™¯"""
    prediction_service = PredictionService()

    services = ["user-service", "product-service", "order-service"]

    print("ğŸ”® å¼€å§‹é¢„æµ‹æ€§ç»´æŠ¤åˆ†æ...\n")

    for service in services:
        print(f"--- åˆ†ææœåŠ¡ï¼š{service} ---")

        # 1. å®¹é‡é¢„æµ‹
        print("ğŸ“Š å®¹é‡é¢„æµ‹ï¼š")
        capacity = await prediction_service.predict_capacity(service, hours=24)

        print(f"  é¢„æµ‹å³°å€¼CPU: {capacity['recommendations']['peak_cpu']:.2f}%")
        print(f"  é¢„æµ‹å¹³å‡CPU: {capacity['recommendations']['avg_cpu']:.2f}%")
        print(f"  æ¨èå‰¯æœ¬æ•°: {capacity['recommendations']['recommended_replicas']}")

        # 2. æ•…éšœé¢„æµ‹
        print("\nâš ï¸  æ•…éšœé¢„æµ‹ï¼š")
        failure = await prediction_service.predict_failure(service, hours=24)

        probability = failure['failure_probability'] * 100
        print(f"  æ•…éšœæ¦‚ç‡: {probability:.1f}%")
        print(f"  ç½®ä¿¡åº¦: {failure['confidence']}")

        if probability > 70:
            print(f"  ğŸš¨ é«˜é£é™©ï¼å»ºè®®é‡‡å–é¢„é˜²æªæ–½")
            print(f"  é£é™©å› ç´ ï¼š{failure.get('risk_factors', [])}")
            print(f"  é¢„é˜²æªæ–½ï¼š{failure.get('preventive_actions', [])}")

            # æå‰é‡‡å–æªæ–½
            print("\nğŸ’Š æ‰§è¡Œé¢„é˜²æ€§ç»´æŠ¤...")
            from app.services.healing_service import AutoHealingService
            healing_service = AutoHealingService()

            result = await healing_service.analyze_and_heal(
                service,
                {"type": "preventive", "severity": "medium"}
            )
            print(f"  ç»´æŠ¤ç»“æœï¼š{result}")

        print()

# è¿è¡Œåœºæ™¯
asyncio.run(predictive_maintenance_scenario())
```

---

## éƒ¨ç½²æŒ‡å—

### 1. æœ¬åœ°å¼€å‘

```bash
# å®‰è£…ä¾èµ–
pip install -r backend/requirements.txt

# é…ç½®ç¯å¢ƒå˜é‡
cp backend/.env.example backend/.env
# ç¼–è¾‘ .env æ–‡ä»¶

# å¯åŠ¨åç«¯
cd backend
uvicorn app.main:app --reload --port 8000

# å¯åŠ¨å‰ç«¯
cd frontend
npm install
npm run dev
```

### 2. Kuberneteséƒ¨ç½²

**éƒ¨ç½²æ¸…å•**

```yaml
# infrastructure/kubernetes/aiops-platform.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: aiops

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: aiops-backend
  namespace: aiops
spec:
  replicas: 2
  selector:
    matchLabels:
      app: aiops-backend
  template:
    metadata:
      labels:
        app: aiops-backend
    spec:
      containers:
      - name: api
        image: myorg/aiops-backend:latest
        ports:
        - containerPort: 8000
        env:
        - name: OPENAI_API_KEY
          valueFrom:
            secretKeyRef:
              name: aiops-secrets
              key: openai-api-key
        - name: PROMETHEUS_URL
          value: "http://prometheus.monitoring.svc.cluster.local:9090"
        - name: ELASTICSEARCH_URL
          value: "http://elasticsearch.logging.svc.cluster.local:9200"
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "1Gi"
            cpu: "1000m"

---
apiVersion: v1
kind: Service
metadata:
  name: aiops-backend
  namespace: aiops
spec:
  selector:
    app: aiops-backend
  ports:
  - port: 80
    targetPort: 8000
  type: ClusterIP

---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: aiops-ingress
  namespace: aiops
  annotations:
    kubernetes.io/ingress.class: nginx
    cert-manager.io/cluster-issuer: letsencrypt-prod
spec:
  tls:
  - hosts:
    - aiops.example.com
    secretName: aiops-tls
  rules:
  - host: aiops.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: aiops-backend
            port:
              number: 80
```

**éƒ¨ç½²åˆ°Kubernetes**

```bash
# åˆ›å»ºnamespace
kubectl create namespace aiops

# åˆ›å»ºsecret
kubectl create secret generic aiops-secrets \
  --from-literal=openai-api-key=your-api-key \
  -n aiops

# éƒ¨ç½²åº”ç”¨
kubectl apply -f infrastructure/kubernetes/aiops-platform.yaml

# æŸ¥çœ‹çŠ¶æ€
kubectl get pods -n aiops
kubectl logs -f deployment/aiops-backend -n aiops
```

---

## å­¦ä¹ æˆæœ

å®Œæˆæœ¬é¡¹ç›®åï¼Œä½ å°†æŒæ¡ï¼š

âœ… **AIOpsæ ¸å¿ƒæ¦‚å¿µ**
- å¼‚å¸¸æ£€æµ‹ç®—æ³•
- æ—¶é—´åºåˆ—é¢„æµ‹
- AIé©±åŠ¨çš„æ•…éšœè¯Šæ–­

âœ… **æœºå™¨å­¦ä¹ å®è·µ**
- Isolation Forest
- Prophetæ—¶é—´åºåˆ—é¢„æµ‹
- ç‰¹å¾å·¥ç¨‹

âœ… **LLMåº”ç”¨**
- LangChainæ¡†æ¶
- Agentå¼€å‘
- Tool use

âœ… **è¿ç»´è‡ªåŠ¨åŒ–**
- æ™ºèƒ½å‘Šè­¦
- è‡ªåŠ¨è‡ªæ„ˆ
- é¢„æµ‹æ€§ç»´æŠ¤

âœ… **ç³»ç»Ÿé›†æˆ**
- Prometheusé›†æˆ
- Elasticsearché›†æˆ
- Kubernetes API

---

## æ‰©å±•ç»ƒä¹ 

- [ ] å®ç°æ›´å¤æ‚çš„å¼‚å¸¸æ£€æµ‹ç®—æ³•
- [ ] é›†æˆæ›´å¤šMLæ¨¡å‹ï¼ˆLSTMã€XGBoostï¼‰
- [ ] å®ç°æ ¹å› åˆ†æï¼ˆRCAï¼‰
- [ ] æ·»åŠ è‡ªç„¶è¯­è¨€æŸ¥è¯¢æ¥å£
- [ ] å®ç°æ™ºèƒ½å®¹é‡è§„åˆ’

---

**é¡¹ç›®éš¾åº¦**ï¼šâ­â­â­â­â­
**é¢„è®¡æ—¶é—´**ï¼š80-100å°æ—¶
**é€‚åˆäººç¾¤**ï¼šæœ‰Pythonå’Œè¿ç»´åŸºç¡€ï¼Œæƒ³å­¦ä¹ AIåœ¨è¿ç»´é¢†åŸŸçš„åº”ç”¨
