---
title: AI ä¼ä¸šçº§å®æˆ˜é¡¹ç›®2
description: AIæ™ºèƒ½å®¢æœç³»ç»Ÿå®Œæ•´å®ç°
---

# ï¼šAI å®Œå…¨å®æˆ˜é¡¹ç›® - ä¼ä¸šçº§æ™ºèƒ½å®¢æœç³»ç»Ÿ

> **é¡¹ç›®æ¦‚è¿°**ï¼šæœ¬é¡¹ç›®æ˜¯ä¸€ä¸ªå®Œæ•´çš„ä¼ä¸šçº§AIæ™ºèƒ½å®¢æœç³»ç»Ÿï¼Œé›†æˆå¤§è¯­è¨€æ¨¡å‹ã€çŸ¥è¯†åº“ã€å¤šæ¸ é“æ¥å…¥ã€å·¥å•ç³»ç»Ÿç­‰åŠŸèƒ½ã€‚
>
> **å­¦ä¹ ç›®æ ‡**ï¼š
> - æŒæ¡AIå®¢æœç³»ç»Ÿçš„å®Œæ•´æ¶æ„è®¾è®¡
> - ç†Ÿç»ƒä½¿ç”¨RAGæŠ€æœ¯æ„å»ºä¼ä¸šçŸ¥è¯†åº“
> - æŒæ¡å¤šæ¸ é“æ¥å…¥ï¼ˆç½‘ç«™ã€å¾®ä¿¡ã€å°ç¨‹åºï¼‰
> - å­¦ä¼šå¯¹è¯ç®¡ç†ã€æ„å›¾è¯†åˆ«ã€å·¥å•æµè½¬

---

## é¡¹ç›®ä»‹ç»

### é¡¹ç›®èƒŒæ™¯

æœ¬AIæ™ºèƒ½å®¢æœç³»ç»Ÿæ˜¯ä¸€ä¸ªå®Œæ•´çš„ä¼ä¸šçº§å®¢æœè§£å†³æ–¹æ¡ˆï¼Œä¸»è¦åŠŸèƒ½åŒ…æ‹¬ï¼š

- âœ… **æ™ºèƒ½å¯¹è¯**ï¼šåŸºäºLLMçš„è‡ªç„¶è¯­è¨€å¯¹è¯
- âœ… **çŸ¥è¯†åº“ç®¡ç†**ï¼šä¼ä¸šæ–‡æ¡£ã€FAQã€äº§å“ä¿¡æ¯
- âœ… **RAGæ£€ç´¢**ï¼šå‘é‡æ•°æ®åº“ã€è¯­ä¹‰æœç´¢
- âœ… **å¤šæ¸ é“æ¥å…¥**ï¼šç½‘ç«™widgetã€å¾®ä¿¡å…¬ä¼—å·ã€å°ç¨‹åº
- âœ… **äººå·¥åä½œ**ï¼šæ™ºèƒ½è½¬äººå·¥ã€å·¥å•ç³»ç»Ÿ
- âœ… **æ•°æ®åˆ†æ**ï¼šå¯¹è¯åˆ†æã€æ»¡æ„åº¦ç»Ÿè®¡
- âœ… **æ„å›¾è¯†åˆ«**ï¼šè‡ªåŠ¨åˆ†ç±»ã€è·¯ç”±åˆ†å‘
- âœ… **å¤šè¯­è¨€æ”¯æŒ**ï¼šä¸­è‹±æ–‡ã€å®æ—¶ç¿»è¯‘

### æŠ€æœ¯æ ˆ

| ç±»åˆ« | æŠ€æœ¯é€‰å‹ | ç‰ˆæœ¬ |
|------|---------|------|
| **å‰ç«¯** | Vue3 + TypeScript | latest |
| **åç«¯** | Python + FastAPI | latest |
| **LLM** | OpenAI GPT-4 / Claude 3 | latest |
| **å‘é‡åº“** | Pinecone / Weaviate | latest |
| **æ•°æ®åº“** | PostgreSQL + pgvector | latest |
| **æ¶ˆæ¯é˜Ÿåˆ—** | Redis + Celery | latest |
| **WebSocket** | Socket.io | latest |
| **å‰ç«¯SDK** | React / Vue SDK | latest |

### é¡¹ç›®ç»“æ„

```
ai-customer-service/
â”œâ”€â”€ frontend/                     # å‰ç«¯ï¼ˆç®¡ç†åå°ï¼‰
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ views/
â”‚   â”‚   â”‚   â”œâ”€â”€ dashboard/       # ä»ªè¡¨ç›˜
â”‚   â”‚   â”‚   â”œâ”€â”€ chat/            # å¯¹è¯ç®¡ç†
â”‚   â”‚   â”‚   â”œâ”€â”€ knowledge/       # çŸ¥è¯†åº“
â”‚   â”‚   â”‚   â”œâ”€â”€ tickets/         # å·¥å•ç³»ç»Ÿ
â”‚   â”‚   â”‚   â””â”€â”€ analytics/       # æ•°æ®åˆ†æ
â”‚   â”‚   â”œâ”€â”€ components/          # ç»„ä»¶
â”‚   â”‚   â””â”€â”€ stores/              # çŠ¶æ€ç®¡ç†
â”œâ”€â”€ backend/                      # åç«¯
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/                 # APIè·¯ç”±
â”‚   â”‚   â”œâ”€â”€ core/                # æ ¸å¿ƒåŠŸèƒ½
â”‚   â”‚   â”‚   â”œâ”€â”€ llm/             # LLMé›†æˆ
â”‚   â”‚   â”‚   â”œâ”€â”€ rag/             # RAGæ£€ç´¢
â”‚   â”‚   â”‚   â”œâ”€â”€ dialog/          # å¯¹è¯ç®¡ç†
â”‚   â”‚   â”‚   â””â”€â”€ intent/          # æ„å›¾è¯†åˆ«
â”‚   â”‚   â”œâ”€â”€ models/              # æ•°æ®æ¨¡å‹
â”‚   â”‚   â””â”€â”€ services/            # ä¸šåŠ¡é€»è¾‘
â”œâ”€â”€ chat-widget/                  # èŠå¤©ç»„ä»¶
â”‚   â”œâ”€â”€ react-widget/            # Reactç‰ˆæœ¬
â”‚   â””â”€â”€ vue-widget/              # Vueç‰ˆæœ¬
â”œâ”€â”€ integration/                  # ç¬¬ä¸‰æ–¹é›†æˆ
â”‚   â”œâ”€â”€ wechat/                  # å¾®ä¿¡
â”‚   â””â”€â”€ slack/                   # Slack
â””â”€â”€ scripts/                      # è„šæœ¬å·¥å…·
    â”œâ”€â”€ embedding.py             # å‘é‡åŒ–
    â””â”€â”€ import_kb.py             # å¯¼å…¥çŸ¥è¯†åº“
```

---

## æ•°æ®åº“è®¾è®¡

### 1. æ•°æ®æ¨¡å‹

```python
# backend/app/models/models.py
from sqlalchemy import Column, String, Text, Integer, Float, DateTime, ForeignKey, JSON
from sqlalchemy.orm import relationship
from datetime import datetime

class Conversation(Base):
    __tablename__ = "conversations"

    id = Column(String, primary_key=True)
    channel = Column(String)  # web, wechat, slack
    customer_id = Column(String)
    status = Column(String)  # active, closed, transferred
    assigned_agent_id = Column(String, ForeignKey("agents.id"))
    messages = relationship("Message", back_populates="conversation")
    metadata = Column(JSON)
    created_at = Column(DateTime, default=datetime.utcnow)

class Message(Base):
    __tablename__ = "messages"

    id = Column(String, primary_key=True)
    conversation_id = Column(String, ForeignKey("conversations.id"))
    role = Column(String)  # user, bot, agent
    content = Column(Text)
    intent = Column(String)
    confidence = Column(Float)
    metadata = Column(JSON)
    conversation = relationship("Conversation", back_populates="messages")
    created_at = Column(DateTime, default=datetime.utcnow)

class KnowledgeBase(Base):
    __tablename__ = "knowledge_base"

    id = Column(String, primary_key=True)
    title = Column(String)
    content = Column(Text)
    category = Column(String)
    embedding = Column(JSON)  # å‘é‡åµŒå…¥
    metadata = Column(JSON)
    created_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)

class Ticket(Base):
    __tablename__ = "tickets"

    id = Column(String, primary_key=True)
    conversation_id = Column(String, ForeignKey("conversations.id"))
    title = Column(String)
    description = Column(Text)
    priority = Column(String)  # low, medium, high, urgent
    status = Column(String)  # open, in_progress, resolved, closed
    assigned_to = Column(String, ForeignKey("agents.id"))
    created_at = Column(DateTime, default=datetime.utcnow)
    resolved_at = Column(DateTime)

class Agent(Base):
    __tablename__ = "agents"

    id = Column(String, primary_key=True)
    name = Column(String)
    email = Column(String)
    status = Column(String)  # online, offline, away
    skills = Column(JSON)  # æŠ€èƒ½æ ‡ç­¾
    max_concurrent_chats = Column(Integer, default=5)
    active_chats = Column(Integer, default=0)
```

---

## æ ¸å¿ƒåŠŸèƒ½å®ç°

### 1. RAGçŸ¥è¯†åº“ç³»ç»Ÿ

```python
# backend/app/core/rag/retreiver.py
from typing import List, Optional
from langchain.vectorstores import Pinecone
from langchain.embeddings import OpenAIEmbeddings
from langchain.chat_models import ChatOpenAI
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory

class RAGRetriever:
    def __init__(self):
        self.embeddings = OpenAIEmbeddings()
        self.vectorstore = Pinecone.from_existing_index(
            index_name="customer-service-kb",
            embedding=self.embeddings
        )
        self.llm = ChatOpenAI(model="gpt-4", temperature=0)

    def retrieve(self, query: str, top_k: int = 3) -> List[str]:
        """æ£€ç´¢ç›¸å…³æ–‡æ¡£"""
        docs = self.vectorstore.similarity_search(
            query=query,
            k=top_k
        )
        return [doc.page_content for doc in docs]

    def answer(self, query: str, conversation_history: List[dict]) -> str:
        """åŸºäºRAGç”Ÿæˆå›ç­”"""
        memory = ConversationBufferMemory(
            return_messages=True,
            memory_key="chat_history"
        )

        # åŠ è½½å†å²å¯¹è¯
        for msg in conversation_history:
            if msg["role"] == "user":
                memory.chat_memory.add_user_message(msg["content"])
            else:
                memory.chat_memory.add_ai_message(msg["content"])

        # åˆ›å»ºæ£€ç´¢é“¾
        qa_chain = ConversationalRetrievalChain.from_llm(
            llm=self.llm,
            retriever=self.vectorstore.as_retriever(search_kwargs={"k": 3}),
            memory=memory,
            return_source_documents=True
        )

        result = qa_chain({"question": query})

        return {
            "answer": result["answer"],
            "sources": [doc.metadata for doc in result["source_documents"]]
        }
```

### 2. å¯¹è¯ç®¡ç†ç³»ç»Ÿ

```python
# backend/app/core/dialog/manager.py
from typing import List, Optional
from app.models.models import Conversation, Message
from app.core.llm.openai_client import OpenAIClient
from app.core.rag.retriever import RAGRetriever
from app.core.intent.classifier import IntentClassifier

class DialogManager:
    def __init__(self):
        self.llm = OpenAIClient()
        self.rag = RAGRetriever()
        self.intent_classifier = IntentClassifier()

    async def process_message(
        self,
        conversation_id: str,
        user_message: str,
        customer_id: str
    ) -> dict:
        """å¤„ç†ç”¨æˆ·æ¶ˆæ¯"""

        # 1. è·å–å¯¹è¯å†å²
        conversation = await self.get_conversation(conversation_id)
        history = await self.get_message_history(conversation_id)

        # 2. æ„å›¾è¯†åˆ«
        intent_result = await self.intent_classifier.classify(
            message=user_message,
            history=history
        )

        # 3. åˆ¤æ–­æ˜¯å¦éœ€è¦è½¬äººå·¥
        if intent_result["should_transfer_to_human"]:
            return await self.transfer_to_agent(
                conversation_id=conversation_id,
                reason=intent_result["reason"]
            )

        # 4. RAGæ£€ç´¢å›ç­”
        if intent_result["needs_knowledge_search"]:
            rag_result = self.rag.answer(
                query=user_message,
                conversation_history=history
            )
            bot_answer = rag_result["answer"]
            sources = rag_result["sources"]
        else:
            # ç›´æ¥ä½¿ç”¨LLMç”Ÿæˆå›ç­”
            bot_answer = await self.llm.chat(
                messages=[
                    *history,
                    {"role": "user", "content": user_message}
                ],
                system_prompt=self._get_system_prompt(intent_result["intent"])
            )
            sources = []

        # 5. ä¿å­˜æ¶ˆæ¯
        await self.save_message(
            conversation_id=conversation_id,
            role="user",
            content=user_message,
            intent=intent_result["intent"],
            confidence=intent_result["confidence"]
        )

        await self.save_message(
            conversation_id=conversation_id,
            role="bot",
            content=bot_answer,
            metadata={"sources": sources}
        )

        return {
            "answer": bot_answer,
            "intent": intent_result["intent"],
            "confidence": intent_result["confidence"],
            "sources": sources
        }

    def _get_system_prompt(self, intent: str) -> str:
        """æ ¹æ®æ„å›¾è·å–ç³»ç»Ÿæç¤ºè¯"""
        prompts = {
            "greeting": "ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„å®¢æœåŠ©æ‰‹ï¼Œçƒ­æƒ…åœ°é—®å€™ç”¨æˆ·ã€‚",
            "complaint": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å®¢æœï¼Œè€å¿ƒå€¾å¬ç”¨æˆ·çš„æŠ•è¯‰ï¼Œå¹¶è¡¨ç¤ºç†è§£å’ŒåŒæƒ…ã€‚",
            "inquiry": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å®¢æœï¼Œæ¸…æ™°å‡†ç¡®åœ°å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚",
            "technical_support": "ä½ æ˜¯ä¸€ä¸ªæŠ€æœ¯æ”¯æŒä¸“å®¶ï¼Œæä¾›ä¸“ä¸šçš„æŠ€æœ¯æŒ‡å¯¼ã€‚"
        }
        return prompts.get(intent, "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å®¢æœåŠ©æ‰‹ã€‚")
```

### 3. æ„å›¾è¯†åˆ«ç³»ç»Ÿ

```python
# backend/app/core/intent/classifier.py
from typing import List, Dict
from langchain.prompts import ChatPromptTemplate
from langchain.chat_models import ChatOpenAI
from langchain.output_parsers import PydanticOutputParser
from pydantic import BaseModel, Field

class IntentClassification(BaseModel):
    intent: str = Field(description="ç”¨æˆ·æ„å›¾ç±»åˆ«")
    confidence: float = Field(description="ç½®ä¿¡åº¦ï¼Œ0-1ä¹‹é—´")
    should_transfer_to_human: bool = Field(description="æ˜¯å¦éœ€è¦è½¬äººå·¥")
    reason: str = Field(description="è½¬äººå·¥çš„åŸå› ")
    needs_knowledge_search: bool = Field(description="æ˜¯å¦éœ€è¦æ£€ç´¢çŸ¥è¯†åº“")

class IntentClassifier:
    def __init__(self):
        self.llm = ChatOpenAI(model="gpt-4", temperature=0)
        self.parser = PydanticOutputParser(pydantic_object=IntentClassification)

        self.intents = {
            "greeting": "é—®å€™ã€æ‰“æ‹›å‘¼",
            "farewell": "å‘Šåˆ«ã€é“åˆ«",
            "complaint": "æŠ•è¯‰ã€æŠ±æ€¨",
            "inquiry": "å’¨è¯¢ã€è¯¢é—®",
            "technical_support": "æŠ€æœ¯æ”¯æŒ",
            "billing": "è´¦å•ã€ä»˜æ¬¾",
            "refund": "é€€æ¬¾",
            "order_status": "è®¢å•çŠ¶æ€æŸ¥è¯¢",
            "product_info": "äº§å“ä¿¡æ¯",
            "other": "å…¶ä»–"
        }

    async def classify(
        self,
        message: str,
        history: List[dict]
    ) -> Dict:
        """è¯†åˆ«ç”¨æˆ·æ„å›¾"""

        prompt = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯ä¸€ä¸ªå®¢æœæ„å›¾åˆ†ç±»å™¨ã€‚

            å¯ç”¨çš„æ„å›¾ç±»åˆ«ï¼š
            {intents}

            è¯·åˆ¤æ–­ç”¨æˆ·æ¶ˆæ¯çš„æ„å›¾ï¼Œå¹¶è¿”å›JSONæ ¼å¼ç»“æœã€‚

            {format_instructions}

            åˆ¤æ–­è§„åˆ™ï¼š
            1. å¦‚æœç”¨æˆ·è¡¨è¾¾å¼ºçƒˆä¸æ»¡ã€å¨èƒè¦æŠ•è¯‰ã€æˆ–è€…è¿ç»­å¤šæ¬¡æé—®æœªå¾—åˆ°æ»¡æ„ç­”æ¡ˆï¼Œshould_transfer_to_humanè®¾ä¸ºtrue
            2. å¦‚æœç”¨æˆ·è¯¢é—®å…·ä½“çš„äº§å“ã€è®¢å•ã€æ”¿ç­–ç­‰ä¿¡æ¯ï¼Œneeds_knowledge_searchè®¾ä¸ºtrue
            3. å¦‚æœæ˜¯ç®€å•çš„å¯’æš„ï¼Œneeds_knowledge_searchè®¾ä¸ºfalse
            """),
            ("human", "ç”¨æˆ·æ¶ˆæ¯ï¼š{message}\nå¯¹è¯å†å²ï¼š{history}")
        ])

        chain = prompt | self.llm | self.parser

        result = await chain.ainvoke({
            "intents": "\n".join([f"{k}: {v}" for k, v in self.intents.items()]),
            "format_instructions": self.parser.get_format_instructions(),
            "message": message,
            "history": "\n".join([f"{m['role']}: {m['content']}" for m in history[-5:]])
        })

        return result.dict()
```

### 4. èŠå¤©Widgetç»„ä»¶

```tsx
// chat-widget/react-widget/src/ChatWidget.tsx
import React, { useState, useEffect, useRef } from 'react'

interface Message {
  id: string
  role: 'user' | 'bot' | 'agent'
  content: string
  timestamp: Date
}

export const ChatWidget: React.FC = () => {
  const [isOpen, setIsOpen] = useState(false)
  const [messages, setMessages] = useState<Message[]>([])
  const [inputValue, setInputValue] = useState('')
  const [isTyping, setIsTyping] = useState(false)
  const [conversationId, setConversationId] = useState<string>('')
  const messagesEndRef = useRef<HTMLDivElement>(null)

  const scrollToBottom = () => {
    messagesEndRef.current?.scrollIntoView({ behavior: "smooth" })
  }

  useEffect(() => {
    scrollToBottom()
  }, [messages])

  const handleSendMessage = async () => {
    if (!inputValue.trim()) return

    const userMessage: Message = {
      id: Date.now().toString(),
      role: 'user',
      content: inputValue,
      timestamp: new Date()
    }

    setMessages(prev => [...prev, userMessage])
    setInputValue('')
    setIsTyping(true)

    try {
      const response = await fetch('/api/chat/message', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          message: inputValue,
          conversation_id: conversationId
        })
      })

      const data = await response.json()

      const botMessage: Message = {
        id: data.message_id,
        role: 'bot',
        content: data.answer,
        timestamp: new Date()
      }

      setMessages(prev => [...prev, botMessage])

      if (data.conversation_id) {
        setConversationId(data.conversation_id)
      }
    } catch (error) {
      console.error('å‘é€æ¶ˆæ¯å¤±è´¥:', error)
    } finally {
      setIsTyping(false)
    }
  }

  return (
    <div className="chat-widget-container">
      {/* èŠå¤©æŒ‰é’® */}
      {!isOpen && (
        <button
          onClick={() => setIsOpen(true)}
          className="chat-button"
        >
          ğŸ’¬
        </button>
      )}

      {/* èŠå¤©çª—å£ */}
      {isOpen && (
        <div className="chat-window">
          <div className="chat-header">
            <h3>å®¢æœåŠ©æ‰‹</h3>
            <button onClick={() => setIsOpen(false)}>Ã—</button>
          </div>

          <div className="chat-messages">
            {messages.map(msg => (
              <div
                key={msg.id}
                className={`message ${msg.role}`}
              >
                <div className="message-content">
                  {msg.content}
                </div>
                <div className="message-time">
                  {new Date(msg.timestamp).toLocaleTimeString()}
                </div>
              </div>
            ))}

            {isTyping && (
              <div className="message bot typing">
                <div className="typing-indicator">
                  <span></span>
                  <span></span>
                  <span></span>
                </div>
              </div>
            )}

            <div ref={messagesEndRef} />
          </div>

          <div className="chat-input">
            <input
              type="text"
              value={inputValue}
              onChange={(e) => setInputValue(e.target.value)}
              onKeyPress={(e) => e.key === 'Enter' && handleSendMessage()}
              placeholder="è¾“å…¥æ‚¨çš„é—®é¢˜..."
            />
            <button onClick={handleSendMessage}>
              å‘é€
            </button>
          </div>
        </div>
      )}
    </div>
  )
}
```

### 5. WebSocketå®æ—¶é€šä¿¡

```python
# backend/app/api/websocket.py
from fastapi import WebSocket
from typing import Dict
import json
import asyncio

class ConnectionManager:
    def __init__(self):
        self.active_connections: Dict[str, WebSocket] = {}

    async def connect(self, websocket: WebSocket, conversation_id: str):
        await websocket.accept()
        self.active_connections[conversation_id] = websocket

    def disconnect(self, conversation_id: str):
        if conversation_id in self.active_connections:
            del self.active_connections[conversation_id]

    async def send_message(self, conversation_id: str, message: dict):
        if conversation_id in self.active_connections:
            await self.active_connections[conversation_id].send_json(message)

manager = ConnectionManager()

@app.websocket("/ws/chat/{conversation_id}")
async def chat_websocket(websocket: WebSocket, conversation_id: str):
    await manager.connect(websocket, conversation_id)

    try:
        while True:
            data = await websocket.receive_json()

            # å¤„ç†æ¶ˆæ¯
            result = await dialog_manager.process_message(
                conversation_id=conversation_id,
                user_message=data["message"],
                customer_id=data.get("customer_id", "")
            )

            # å‘é€å›å¤
            await manager.send_message(conversation_id, {
                "type": "bot_response",
                "data": result
            })

    except WebSocketDisconnect:
        manager.disconnect(conversation_id)
```

### 6. å·¥å•ç³»ç»Ÿ

```python
# backend/app/core/ticket/system.py
from typing import Optional
from app.models.models import Ticket, Conversation

class TicketSystem:
    async def create_ticket(
        self,
        conversation_id: str,
        title: str,
        description: str,
        priority: str = "medium"
    ) -> Ticket:
        """åˆ›å»ºå·¥å•"""

        ticket = Ticket(
            id=self._generate_ticket_id(),
            conversation_id=conversation_id,
            title=title,
            description=description,
            priority=priority,
            status="open"
        )

        # æ™ºèƒ½åˆ†é…å®¢æœ
        assigned_agent = await self._assign_agent(ticket)
        ticket.assigned_to = assigned_agent.id

        await self.save_ticket(ticket)

        # é€šçŸ¥å®¢æœ
        await self._notify_agent(assigned_agent, ticket)

        return ticket

    async def _assign_agent(self, ticket: Ticket) -> Agent:
        """æ™ºèƒ½åˆ†é…å®¢æœ"""
        # åŸºäºæŠ€èƒ½åŒ¹é…ã€å½“å‰è´Ÿè½½ç­‰å› ç´ åˆ†é…
        available_agents = await self.get_available_agents()

        # æ‰¾åˆ°æŠ€èƒ½åŒ¹é…çš„å®¢æœ
        skilled_agents = [
            agent for agent in available_agents
            if self._skill_match(agent.skills, ticket)
        ]

        if not skilled_agents:
            skilled_agents = available_agents

        # é€‰æ‹©å½“å‰è´Ÿè½½æœ€ä½çš„å®¢æœ
        return min(skilled_agents, key=lambda a: a.active_chats)

    def _skill_match(self, agent_skills: dict, ticket: Ticket) -> bool:
        """æ£€æŸ¥æŠ€èƒ½åŒ¹é…åº¦"""
        # å®ç°æŠ€èƒ½åŒ¹é…é€»è¾‘
        return True
```

---

## æ€§èƒ½ä¼˜åŒ–

### 1. ç¼“å­˜ç­–ç•¥

```python
# backend/app/core/cache/redis_cache.py
import redis
import json
from typing import Any, Optional

class RedisCache:
    def __init__(self):
        self.redis = redis.Redis(
            host='localhost',
            port=6379,
            db=0,
            decode_responses=True
        )

    async def get(self, key: str) -> Optional[Any]:
        value = await self.redis.get(key)
        return json.loads(value) if value else None

    async def set(self, key: str, value: Any, ttl: int = 3600):
        await self.redis.setex(
            key,
            ttl,
            json.dumps(value)
        )

    async def delete(self, key: str):
        await self.redis.delete(key)

# ä½¿ç”¨ç¤ºä¾‹
cache = RedisCache()

async def get_knowledge_base(query: str):
    cache_key = f"kb:{query}"

    # å…ˆæŸ¥ç¼“å­˜
    cached = await cache.get(cache_key)
    if cached:
        return cached

    # ç¼“å­˜æœªå‘½ä¸­ï¼ŒæŸ¥è¯¢æ•°æ®åº“
    result = await rag_retriever.retrieve(query)

    # å†™å…¥ç¼“å­˜
    await cache.set(cache_key, result, ttl=1800)

    return result
```

### 2. å¼‚æ­¥å¤„ç†

```python
# backend/app/core/async/tasks.py
from celery import Celery

celery_app = Celery('tasks', broker='redis://localhost:6379/0')

@celery_app.task
async def send_email_notification(to: str, subject: str, body: str):
    """å¼‚æ­¥å‘é€é‚®ä»¶"""
    # å‘é€é‚®ä»¶é€»è¾‘
    pass

@celery_app.task
async def generate_analytics_report(conversation_id: str):
    """å¼‚æ­¥ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
    # ç”ŸæˆæŠ¥å‘Šé€»è¾‘
    pass
```

---

## éƒ¨ç½²ä¸Šçº¿

### 1. Docker Compose

```yaml
version: '3.8'

services:
  frontend:
    build: ./frontend
    ports:
      - "3000:3000"

  backend:
    build: ./backend
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://user:pass@db:5432/cs
      - REDIS_URL=redis://redis:6379
      - OPENAI_API_KEY=${OPENAI_API_KEY}
    depends_on:
      - db
      - redis

  db:
    image: postgres:15
    environment:
      - POSTGRES_DB=cs
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=pass
    volumes:
      - pgdata:/var/lib/postgresql/data

  redis:
    image: redis:7-alpine

  worker:
    build: ./backend
    command: celery -A app.core.async.tasks worker --loglevel=info
    depends_on:
      - redis

volumes:
  pgdata:
```

---

## é¡¹ç›®æ€»ç»“

æœ¬é¡¹ç›®æ¶µç›–äº†AIæ™ºèƒ½å®¢æœç³»ç»Ÿå¼€å‘çš„æ ¸å¿ƒæŠ€èƒ½ï¼š

âœ… **æŠ€æœ¯æ ˆ**ï¼šPython + FastAPI + Vue3 + LLM + å‘é‡æ•°æ®åº“
âœ… **æ ¸å¿ƒåŠŸèƒ½**ï¼šæ™ºèƒ½å¯¹è¯ã€çŸ¥è¯†åº“ã€å¤šæ¸ é“æ¥å…¥ã€å·¥å•ç³»ç»Ÿ
âœ… **AIç‰¹æ€§**ï¼šRAGæ£€ç´¢ã€æ„å›¾è¯†åˆ«ã€å¯¹è¯ç®¡ç†ã€æ™ºèƒ½è·¯ç”±
âœ… **ä¼ä¸šç‰¹æ€§**ï¼šå®æ—¶é€šä¿¡ã€æ•°æ®åˆ†æã€æ™ºèƒ½åˆ†é…ã€æ€§èƒ½ä¼˜åŒ–

é€šè¿‡è¿™ä¸ªé¡¹ç›®ï¼Œä½ å°†æŒæ¡ï¼š
- AIå®¢æœç³»ç»Ÿçš„å®Œæ•´æ¶æ„
- RAGæŠ€æœ¯åœ¨ä¼ä¸šåœºæ™¯çš„åº”ç”¨
- å¯¹è¯ç®¡ç†å’Œæ„å›¾è¯†åˆ«
- å¤šæ¸ é“é›†æˆæ–¹æ¡ˆ
- å·¥å•ç³»ç»Ÿè®¾è®¡
- å®æ—¶é€šä¿¡å®ç°

---

## ä¸‹ä¸€æ­¥å­¦ä¹ 

- [ç¬¬11ç« ï¼šAI Agenté«˜çº§åº”ç”¨](/ai/chapter-05)
- [ç¬¬12ç« ï¼šLangGraphå¤æ‚Agentæ¡†æ¶](/ai/chapter-07#langgraphå¤æ‚agentæ¡†æ¶)
- [ç¬¬13ç« ï¼šAIåº”ç”¨è¯„ä¼°å’Œæµ‹è¯•](/ai/chapter-07#aiåº”ç”¨è¯„ä¼°å’Œæµ‹è¯•)
